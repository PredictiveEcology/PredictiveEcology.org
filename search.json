[
  {
    "objectID": "Packages.html",
    "href": "Packages.html",
    "title": "R Packages",
    "section": "",
    "text": "This is an all-in-one package manager that is simple and focused around a single function, Require. This is different than other approaches to package management such as packrat, checkpoint, and renv as it focuses on a “script-based” solution to a reproducible work flow. Thus, all packages, version numbering, and sources are contained within an R script.\nView on CRAN; GitHub; Website\n\n\n\n\n\nMetapackage for implementing a variety of event-based models, with a focus on spatially explicit models. These include raster-based, event-based, and agent-based models. The core simulation components (provided by SpaDES.core) are built upon a discrete event simulation (DES) framework that facilitates modularity, and easily enables the user to include additional functionality by running user-built simulation modules (see also SpaDES.tools). Included are numerous tools to visualize rasters and other maps (via quickPlot), and caching methods for reproducible simulations (via reproducible). Additional functionality is provided by the SpaDES.addins and SpaDES.shiny packages.\nView on CRAN; GitHub; Website\nSee also:\n\nSpaDES.addins: https://spades-addins.predictiveecology.org\nSpaDES.core: https://spades-core.predictiveecology.org/\nSpaDES.shiny: https://spades-shiny.predictiveecology.org/\nSpaDES.tools: https://spades-tools.predictiveecology.org/\n\n\n\n\n\n\n\nA high-level plotting system, built using grid graphics, that is optimized for speed and modularity. This has great utility for quick visualizations when testing code, with the key benefit that visualizations are updated independently of one another.\nView on CRAN; GitHub; Website\n\n\n\n\n\n\nBuilt on top of git2r and archivist, this package aims at making high-level, robust, machine and OS independent tools for making deeply reproducible and reusable content in R. This extends beyond the package management utilites of packrat and checkpoint by including tools for caching and accessing GitHub repositories.\nView on CRAN; GitHub; Website\n\n\n\n\n\n\nComparisons of floating point numbers are problematic due to errors associated with the binary representation of decimal numbers. Despite being aware of these problems, people still use numerical methods that fail to account for these and other rounding errors (this pitfall is the first to be highlighted in Circle 1 of Burns (2012) The R Inferno). This package provides new relational operators useful for performing floating point number comparisons with a set tolerance.\nView on CRAN; GitHub; Website\n\n\n\n\n\n\nNetLogoR is an R package which aims to help translating agent-based models built in NetLogo (Wilensky, 1999) into R or help directly with creating new agent-based models in R following the NetLogo framework.\nNetLogoR provides the necessary NetLogo’s primitives as well as complementary functions to build agent-based models. A programming guide derived from the NetLogo’s Programming Guide is available.\nThis package is under construction and therefore function errors and mismatches with the documentation may occur.\nView on CRAN; GitHub; Website"
  },
  {
    "objectID": "Packages.html#r-packages",
    "href": "Packages.html#r-packages",
    "title": "R Packages",
    "section": "",
    "text": "This is an all-in-one package manager that is simple and focused around a single function, Require. This is different than other approaches to package management such as packrat, checkpoint, and renv as it focuses on a “script-based” solution to a reproducible work flow. Thus, all packages, version numbering, and sources are contained within an R script.\nView on CRAN; GitHub; Website\n\n\n\n\n\nMetapackage for implementing a variety of event-based models, with a focus on spatially explicit models. These include raster-based, event-based, and agent-based models. The core simulation components (provided by SpaDES.core) are built upon a discrete event simulation (DES) framework that facilitates modularity, and easily enables the user to include additional functionality by running user-built simulation modules (see also SpaDES.tools). Included are numerous tools to visualize rasters and other maps (via quickPlot), and caching methods for reproducible simulations (via reproducible). Additional functionality is provided by the SpaDES.addins and SpaDES.shiny packages.\nView on CRAN; GitHub; Website\nSee also:\n\nSpaDES.addins: https://spades-addins.predictiveecology.org\nSpaDES.core: https://spades-core.predictiveecology.org/\nSpaDES.shiny: https://spades-shiny.predictiveecology.org/\nSpaDES.tools: https://spades-tools.predictiveecology.org/\n\n\n\n\n\n\n\nA high-level plotting system, built using grid graphics, that is optimized for speed and modularity. This has great utility for quick visualizations when testing code, with the key benefit that visualizations are updated independently of one another.\nView on CRAN; GitHub; Website\n\n\n\n\n\n\nBuilt on top of git2r and archivist, this package aims at making high-level, robust, machine and OS independent tools for making deeply reproducible and reusable content in R. This extends beyond the package management utilites of packrat and checkpoint by including tools for caching and accessing GitHub repositories.\nView on CRAN; GitHub; Website\n\n\n\n\n\n\nComparisons of floating point numbers are problematic due to errors associated with the binary representation of decimal numbers. Despite being aware of these problems, people still use numerical methods that fail to account for these and other rounding errors (this pitfall is the first to be highlighted in Circle 1 of Burns (2012) The R Inferno). This package provides new relational operators useful for performing floating point number comparisons with a set tolerance.\nView on CRAN; GitHub; Website\n\n\n\n\n\n\nNetLogoR is an R package which aims to help translating agent-based models built in NetLogo (Wilensky, 1999) into R or help directly with creating new agent-based models in R following the NetLogo framework.\nNetLogoR provides the necessary NetLogo’s primitives as well as complementary functions to build agent-based models. A programming guide derived from the NetLogo’s Programming Guide is available.\nThis package is under construction and therefore function errors and mismatches with the documentation may occur.\nView on CRAN; GitHub; Website"
  },
  {
    "objectID": "Training.html",
    "href": "Training.html",
    "title": "Training",
    "section": "",
    "text": "Title\n\n\nDescription\n\n\n\n\n\n\n\n\n\nSpaDES for Dummies\n\n\nGuide to the SpaDES modelling toolkit in R\n\n\n\n\n\n\n\nCreating and integrating simple models in SpaDES\n\n\nThis guide provides a simple and yet comprehensive guide to creating and then integrating SpaDES compatible modules (hereby “SpaDES modules”).\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "News",
    "section": "",
    "text": "Welcome to the website of the Predictive Ecology Community\nWe are updating these pages over the next weeks; please stay tuned."
  },
  {
    "objectID": "index.html#latest-news",
    "href": "index.html#latest-news",
    "title": "News",
    "section": "Latest news",
    "text": "Latest news"
  },
  {
    "objectID": "bios/current/ana.html",
    "href": "bios/current/ana.html",
    "title": "Ana Raymundo",
    "section": "",
    "text": "webpage\n  \n\n      \n(PhD Student 2018 - )\nAna is working on questions related to forestry and birds across Canada. A student at Laval University, she is currently in Victoria learning the SpaDES ecosystem."
  },
  {
    "objectID": "bios/current/genevieve.html",
    "href": "bios/current/genevieve.html",
    "title": "Geneviève Degré-Timmons",
    "section": "",
    "text": "webpage\n  \n\n      \n(PhD Student 2021 - )\nGeneviève is working on questions related to lichen and caribou in Northwest Territories. A student at Laval University. |"
  },
  {
    "objectID": "bios/sarah.html",
    "href": "bios/sarah.html",
    "title": "Dr. Sarah Bauduin",
    "section": "",
    "text": "webpage\n  \n\n      \n(PhD 2017)"
  },
  {
    "objectID": "bios/sebastien.html",
    "href": "bios/sebastien.html",
    "title": "Sebastien Renard",
    "section": "",
    "text": "webpage\n  \n\n      \n(PhD)"
  },
  {
    "objectID": "bios/alana.html",
    "href": "bios/alana.html",
    "title": "Dr Alana Clason",
    "section": "",
    "text": "webpage\n  \n  \n    \n     GitHub\n  \n\n      \nResearch fellow at the Bulkley Valley Research Centre.\nAlana’s PhD was completed in 2018.\nDissertation title:\nWhitebark pine at the northern edge: current constraints and future potential northern distribution under a changing climate."
  },
  {
    "objectID": "bios/mario.html",
    "href": "bios/mario.html",
    "title": "Mario van Telgen",
    "section": "",
    "text": "webpage\n  \n\n      \n(PhD)"
  },
  {
    "objectID": "bios/community/celine.html",
    "href": "bios/community/celine.html",
    "title": "Dr Céline Boisvenue",
    "section": "",
    "text": "webpage\n  \n  \n    \n     GitHub\n  \n  \n    \n     e-mail\n  \n\n      \nResearch Scientist, Natural Resources Canada\nAdjunct Professor, University of British Columbia\nI am a Research Scientist with the Canadian Forest Service, in Victoria BC. All my research is applied to understanding forests, modelling them as well as possible given available data, to support science-based management and policy development. My research activities provide scientific support for Canada’s greenhouse gas (GHG) balance for forests under international reporting obligations, and contribute to the next generation of models for forest GHG estimates. I was a practicing forester and a biometrics consultant prior to becoming a researcher. I am therefore well positioned to provide viable solutions for both management and policy development. My recent focus has been on regional spatio-temporal modelling and the integration of remotely-sensed products into forest dynamics models. My masters from UBC biometrics (http://biometrics.forestry.ubc.ca/ ), and my PhD is from the Numerical Terradynamic Simulation group (NTSG - http://www.ntsg.umt.edu/), a NASA Earth Science Information Partner (http://www.esipfed.org/) at the University of Montana."
  },
  {
    "objectID": "bios/community/alex.html",
    "href": "bios/community/alex.html",
    "title": "Dr Alex Chubaty",
    "section": "",
    "text": "webpage\n  \n\n      \nPresident, FOR-CAST Research & Analytics\nPreviously, Alex was a Postdoctoral Fellow with the Predictive Ecology group from 2015-2017"
  },
  {
    "objectID": "bios/community/steve.html",
    "href": "bios/community/steve.html",
    "title": "Dr Steve Cumming",
    "section": "",
    "text": "webpage\n  \n  \n    \n     GitHub\n  \n  \n    \n     e-mail\n  \n\n      \nProfessor, Université Laval"
  },
  {
    "objectID": "bios/community/frances.html",
    "href": "bios/community/frances.html",
    "title": "Dr Frances Stewart",
    "section": "",
    "text": "webpage\n  \n\n      \nCanada Research Chair, Northern Wildlife, Laurier University.\nFrances initially joined the Predictive Ecology community as a Postdoctoral Fellow with the from 2019-2021. She is now the head of the Wild Lab at Laurier University."
  },
  {
    "objectID": "posts/2015-05-12-Is-R-fast-enough-04.html",
    "href": "posts/2015-05-12-Is-R-fast-enough-04.html",
    "title": "Is R Fast Enough? - Part 4 - ‘Loops’",
    "section": "",
    "text": "In part 4 of this series on benchmarking R, we’ll explore loops and a common alternative, vectorizing. This is probably the “biggest” issue making people think that R is a slow language. Essentially, other procedural languages use explicit loops; programmers moving from those languages to R start with the same procedures and find that R is slow. We will discuss a range of ways making loops faster and how vectorizing can help.\nThere are many other resources about this topic; we will try to be concise and show the worst case, the best case, and many little steps in between."
  },
  {
    "objectID": "posts/2015-05-12-Is-R-fast-enough-04.html#loops",
    "href": "posts/2015-05-12-Is-R-fast-enough-04.html#loops",
    "title": "Is R Fast Enough? - Part 4 - ‘Loops’",
    "section": "Loops",
    "text": "Loops\nLoops have been the achilles heel of R in the past. In version 3.1 and forward, much of this problem appears to be gone. As could be seen in the https://predictiveecology.org/2015/05/06/Is-R-fast-enough-03.html, pre-allocating a vector and filling it up inside a loop can now be very fast and efficient in native R. To demonstrate these points, below are 6 ways to achieve the same result in R, beginning with a naive loop approach, and working up to the fully vectorized approach. I am using a very fast vectorized function, seq_len, to emphasize the differences between using loops and optimized vectorized functions.\nThe basic code below generates random numbers. The sequence goes from a fully unvectorized, looped structure, with no pre-allocation of the output vector, through to pure vectorized code. The intermediate steps are:\n\nLoop\nLoop with pre-allocated length of output\nsapply (like loops)\nsapply with pipe operator\nvectorized\nvectorized with no intermediate objects\nC++ vectorized\n\n\nlibrary(magrittr) # for pipe %&gt;%\nN = 1e5\n\nmb = microbenchmark::microbenchmark(times=100L,\n\n                                     \n# no pre-allocating of vector length, generating uniform random numbers once, then calling them within each loop\nloopWithNoPreallocate = {\n  set.seed(104)\n  a &lt;- numeric()\n  unifs = runif(N)\n    for (i in 1:N) {\n      a[i] = unifs[i]\n    } \n   a\n  } ,\n\n# pre-allocating vector length, generating uniform random numbers once, then calling them within each loop\nloopWithPreallocate = {\n    set.seed(104)\n    unifs &lt;- runif(N)\n    b &lt;- numeric(N) \n    for (i in 1:N) {\n      b[i] = unifs[i]\n    }\n    b\n  },\n \n# # sapply - generally faster than loops\nsapplyVector1 = {\n      set.seed(104)\n      b &lt;- runif(N) \n      sapply(b,function(x) x)\n      },\n\n# sapply with pipe operator: no intermediate objects are created\nsapplyWithPipe = {\n      set.seed(104)\n      b &lt;- (runif(N)) %&gt;%\n        sapply(.,function(x) x)\n      },\n\n# vectorized with intermediate object before return\nvectorizedWithCopy = {\n    set.seed(104)\n    unifs &lt;- runif(N)\n    unifs\n  },\n\n# no intermediate object before return\nvectorizedWithNoCopy = {\n  set.seed(104)\n  runif(N)\n  }\n\n)\n\nsummary(mb)[c(1,2,5,7)]\n\n                   expr     min   median      max\n1 loopWithNoPreallocate 21.9615 29.84165  89.6070\n2   loopWithPreallocate  7.6051  8.09575  16.7365\n3         sapplyVector1 55.2273 61.30605 111.2397\n4        sapplyWithPipe 52.7653 58.97110 115.2396\n5    vectorizedWithCopy  2.0667  2.21285   6.6799\n6  vectorizedWithNoCopy  2.0717  2.22310   6.0343\n\n# Test that all results return the same vector\nall.equalV(loopWithNoPreallocate, loopWithPreallocate, sapplyVector1, sapplyWithPipe, vectorizedWithCopy, vectorizedWithNoCopy)\n\n[1] TRUE\n\nsumLoops &lt;- round(summary(mb)[[5]],0)\n\nThe fully vectorized function is 15x faster than the fully naive loop. Note also that making as few intermediate objects as possible is faster as well. Comparing vectorizedWithCopy and vectorizedWithNoCopy (where the only difference is making one copy of the object) shows virtually no change. This, I believe, is due to some improvements in after version 3.1 of R that reduces copying for vectors and matrices. Using pipes instead of intermediate objects also did not change the speed very much (slight change by 100%). These are simple tests, and for larger, or more complex objects, in general, it is likely that using pipes will be faster."
  },
  {
    "objectID": "posts/2015-05-12-Is-R-fast-enough-04.html#conclusions",
    "href": "posts/2015-05-12-Is-R-fast-enough-04.html#conclusions",
    "title": "Is R Fast Enough? - Part 4 - ‘Loops’",
    "section": "Conclusions",
    "text": "Conclusions\nWrite vectorized code in R where possible. If not possible, pre-allocate prior to writing loops.\n\nNext time\nWe move on to higher level operations. Specifically, some GIS operations.\n\n\n\nFunctions used\n\nall.equalV = function(...) {\n  vals &lt;- list(...)\n  all(sapply(vals[-1], function(x) all.equal(vals[[1]], x)))\n}\n\n\n\nSystem used:\nTests were done on an HP Z400, Xeon 3.33 GHz processor, running Windows 7 Enterprise, using:\n\n\nR version 4.3.0 (2023-04-21 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 18363)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_Canada.utf8  LC_CTYPE=English_Canada.utf8   \n[3] LC_MONETARY=English_Canada.utf8 LC_NUMERIC=C                   \n[5] LC_TIME=English_Canada.utf8    \n\ntime zone: America/Vancouver\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] magrittr_2.0.3\n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.2     microbenchmark_1.4.10 compiler_4.3.0       \n [4] fastmap_1.1.1         cli_3.6.1             tools_4.3.0          \n [7] htmltools_0.5.5       rstudioapi_0.14       yaml_2.3.7           \n[10] rmarkdown_2.21        knitr_1.42            jsonlite_1.8.4       \n[13] xfun_0.39             digest_0.6.31         rlang_1.1.1          \n[16] evaluate_0.21"
  },
  {
    "objectID": "posts/2015-12-08-R-Web-App-Development-Deployment-Distribution.html",
    "href": "posts/2015-12-08-R-Web-App-Development-Deployment-Distribution.html",
    "title": "R Web App Development, Deployment, and Distribution",
    "section": "",
    "text": "As R language is becoming popular among scientists to build simple we bapplication along simple integration with RShiny, R web applications are being created at a fast rate. RShiny package is not only easy to integrate but also provides a lightweight user interface that is pleasing to the eyes.\nHow is R application developed?\nWhat is the process to deploy and distribute R web applications?"
  },
  {
    "objectID": "posts/2015-12-08-R-Web-App-Development-Deployment-Distribution.html#development",
    "href": "posts/2015-12-08-R-Web-App-Development-Deployment-Distribution.html#development",
    "title": "R Web App Development, Deployment, and Distribution",
    "section": "Development",
    "text": "Development\nWhile web development can be done in many different environments, RStudio is widely used to develop R applications. Below is a snapshot of what RStudio looks like.\n\n\n\nSnapshot of RStudio"
  },
  {
    "objectID": "posts/2015-12-08-R-Web-App-Development-Deployment-Distribution.html#deployment",
    "href": "posts/2015-12-08-R-Web-App-Development-Deployment-Distribution.html#deployment",
    "title": "R Web App Development, Deployment, and Distribution",
    "section": "Deployment",
    "text": "Deployment\n\nPortable Applications\nFor light R application that only needs a local deployment, R portable and web browser portable such as Chrome applications can be used. It does not require as much performance on end user’s side and overall distribution will result in smaller files.\nRefer to this blog post by Lee Peng about Deploying Desktop Apps with R using portable apps\nRefer to this post to package your Shiny application as Windows application\n\n\nShiny Server\nIf you want to put your Shiny application on web, you can host it using Shiny Server. You would need to install, configure and manage the server yourself which could be complicated for some users.\nIf you want an ultimate experience of RShiny, there is also a paid service RShiny Server Pro, where you can host your application on Shiny server. There are a few useful functionalities that comes with the service such as\n\nUser Access Control\nMonitor application performance\nMonitor resource utilization\n\nHowever service is not cheap so if you have extra cash lying around, this would be a quick and easy way to host your application!\nRefer to this to find out more about Shiny Server\n\n\nShinyapps.io\nshinyapps.io is a multi-tenant platform as a service (PaaS) for hosting Shiny web applications. However it can also be expensive since the free edition can be limited depending on your needs.\nRefer to this where you can discover how to get started with shinyapps.io\nIf you cannot decide between shinyapps.io and Shiny Server Pro, refer to this FAQ\nSee below feature comparion chart between Shiny Server, Shiny Server Pro and shinyapps.io taken from this page\n\n\n\n\n\nDocker\nDocker containers wrap up a piece of software in a complete filesystem that contains everything it needs to run:\n\nCode\nRuntime\nSystem tools\nSystem libraries\nAnything you can install on a server\n\nThis guarantees that it will always run the same, regardless of the environment it is running in. While this can be done with a virtual machine, Docker does not use a full OS, it shares the same host kernel meaning that it needs to run on Linux, but it is completely isolated environment. Since Docker containers are lighter than virtual machines, it makes testing much easier because you can always scrap that instance after!\nDocker can come in handy because you can create a Shiny server using few commands which simplifies deployment of a server.\nRefer to this blog post to get your Shiny app ‘dockerized’.\n\n\nOpenCPU HTTP API for R\nOpenCPU is an open source solution for embedded R computing. The software can be freely used, modified and redistributed for both for open source and proprietary projects in academia, industry or elsewhere. All parts of OpenCPU are released under the Apache2 license. The free OpenCPU framework provides a reliable and interoperable HTTP API for R data analysis. You can either call the public servers or download and install OpenCPU’s code on your own servers.\nRefer to this blog post by Jen Underwood on how you can integrate R\n\n\nRook\nRook is a lightweight web server interface for R developed by Jeffrey Horner that does not need any configuration file as Rook is a R package which works out of the box with R HTTP server. The idea behind this is to separate application development from server implementation. Thus, when a web server supports a web server interface, an application written to its specifications is guaranteed to run on that server. So then you would need to do some learning on HTTP to develop Rook applications.\nRefer to this blog post by Ben Ogorek on a tutorial on building simple web application using Rook\nRefer to this CRAN for package description of Rook"
  },
  {
    "objectID": "posts/2015-12-08-R-Web-App-Development-Deployment-Distribution.html#distribution",
    "href": "posts/2015-12-08-R-Web-App-Development-Deployment-Distribution.html#distribution",
    "title": "R Web App Development, Deployment, and Distribution",
    "section": "Distribution",
    "text": "Distribution\nIf your end user has RStudio. then you can share your R files (ui.R and server.R) so that end user can run it through RStudio.\nIf you have your own server, whether it be AWS, Google Cloud, Microsoft Azure, you can share it there.\n\nDocker + Kitematic\nAfter you have ‘dockerized’ your Shiny application, you can share it on Kitematic. Kitematic is a GUI where users can upload and download Docker images to run it in their Docker containers. This makes distributing very simple and easy as Docker Hub can work like App Store! Below is a snapshot of Kitematic.\n\n\n\nRefer to this blog post to learn how you can share your Shiny application with Docker and Kitematic\n\n\nGitHub\nYou can share your code in a repository where other users can contribute by suggestions, corrections and additions. When another user clones your repository, the directory structure is kept so that all data is preserved as where they belong.\n\n\nR Package\nIf you are an awesome R programmer, creating a R package is an useful way to distribute and share within R community. R packages are stored in Comprehensive R Archive Network (CRAN) repository where there is extra level of testing to enforce certain structure so users can ensure quality packages.\nRefer to this blog post on how you can get started on creating a R package by David Smith"
  },
  {
    "objectID": "posts/2021-05-25-missing-cran-packages.html",
    "href": "posts/2021-05-25-missing-cran-packages.html",
    "title": "SpaDES packages archived on CRAN",
    "section": "",
    "text": "Apologies to anyone trying to install reproducible, NetLogoR, and any SpaDES packages from CRAN. We had one of our dependencies (reproducible) temporarily archived, but we are in the process of submitting a fixed version, which should restore the other packages.\nIn the meantime, installing the GitHub versions of reproducible, followed by any other packages should get you back to a working version.\nremotes::install_github(\"PredictiveEcology/reproducible\")\nremotes::install_github(\"PredictiveEcology/SpaDES.core\")"
  },
  {
    "objectID": "posts/2017-09-05-SpaDES-v2.0.0-now-on-CRAN.html",
    "href": "posts/2017-09-05-SpaDES-v2.0.0-now-on-CRAN.html",
    "title": "SpaDES v2.0.0 now on CRAN",
    "section": "",
    "text": "v2.0.0 is now available on CRAN.\nThis is a major update, with several important enhancements and bug fixes.\nMost importantly, the package had become so large that we needed to spilt it into several. The latest package version now acts as a metapackage to install the various spinoff packages:\nThe core simulation components are provided by SpaDES.core), with additonal modelling tools provided by SpaDES.tools). Plotting is provided via quickPlot, and simulation caching methods via reproducible. Additional functionality is provided by the SpaDES.addins and SpaDES.shiny packages.\nThis release also includes several important bug fixes and and performance improvements.\nFor a complete list of changes, see the package’s NEWS file."
  },
  {
    "objectID": "posts/2017-09-05-SpaDES-v2.0.0-now-on-CRAN.html#installation",
    "href": "posts/2017-09-05-SpaDES-v2.0.0-now-on-CRAN.html#installation",
    "title": "SpaDES v2.0.0 now on CRAN",
    "section": "Installation",
    "text": "Installation\nInstall development libraries: building packages from source requires the appropriate development libraries for your operating system.\n\nWindows: install Rtools.\nmacOS: install Xcode commandline tools from the terminal: xcode-select install.\nDebian/Ubuntu Linux: ensure r-base-dev is installed.\n\nSee here for more details.\nInstall suggested packages: the fastshp package can be installed with:\ninstall.packages(\"fastshp\", repos = \"https://rforge.net\", type = \"source\")\n\nCurrent stable release\nInstall from CRAN:\ninstall.packages(\"SpaDES\")\nInstall from GitHub:\n#install.packages(\"devtools\")\nlibrary(\"devtools\")\ninstall_github(\"PredictiveEcology/SpaDES\", dependencies = TRUE) # stable\n\n\nDevelopment version (unstable)\nInstall from GitHub:\n#install.packages(\"devtools\")\nlibrary(\"devtools\")\ninstall_github(\"PredictiveEcology/SpaDES\", ref = \"development\", dependencies = TRUE) # unstable"
  },
  {
    "objectID": "posts/2017-09-05-SpaDES-v2.0.0-now-on-CRAN.html#getting-started",
    "href": "posts/2017-09-05-SpaDES-v2.0.0-now-on-CRAN.html#getting-started",
    "title": "SpaDES v2.0.0 now on CRAN",
    "section": "Getting started",
    "text": "Getting started\n\nGetting started guide\nVignettes\nWiki\nWorkshops"
  },
  {
    "objectID": "posts/2017-09-05-SpaDES-v2.0.0-now-on-CRAN.html#getting-help",
    "href": "posts/2017-09-05-SpaDES-v2.0.0-now-on-CRAN.html#getting-help",
    "title": "SpaDES v2.0.0 now on CRAN",
    "section": "Getting help",
    "text": "Getting help\n\nQ&A Forum"
  },
  {
    "objectID": "posts/2017-09-05-SpaDES-v2.0.0-now-on-CRAN.html#reporting-bugs",
    "href": "posts/2017-09-05-SpaDES-v2.0.0-now-on-CRAN.html#reporting-bugs",
    "title": "SpaDES v2.0.0 now on CRAN",
    "section": "Reporting bugs",
    "text": "Reporting bugs\nThe SpaDES metapackage simply loads a number of other packages from the SpaDES ecosystem. Bug reports should be reported to the specific package in question rather than the metapackage. Contact us via the package’s GitHub site:\n\nquickPlot\nreproducible\nSpaDES.addins\nSpaDES.core\nSpaDES.shiny\nSpaDES.tools"
  },
  {
    "objectID": "posts/2024-04-17-SpaDES Workshop announcement.html",
    "href": "posts/2024-04-17-SpaDES Workshop announcement.html",
    "title": "SpaDES Workshop planning for June 2024 begins",
    "section": "",
    "text": "Survey sent out for planning for SpaDES Workshop.\nDr. Ceres Barros and I will be leading a 2-3 day workshop on training with SpaDES.\nBefore we make final arrangements, we ask to fill out the linked form to help with planning: https://predictiveecology.org/workshops/June-2024-SpaDES-workshop.html\nPrimarily we are asking for:\n\nan email address to send subsequent emails only the individuals who are interested;\nwhether you can do In Person or Virtual, and\npreferred workshop objectives.\n\nThank you,\nEliot and Ceres"
  },
  {
    "objectID": "posts/2015-04-23-Is-R-fast-enough-01.html",
    "href": "posts/2015-04-23-Is-R-fast-enough-01.html",
    "title": "Is R Fast Enough? - Part 1 - ‘The Mean’",
    "section": "",
    "text": "There have been many people, including ourselves, who have asked, “Is R fast enough for simulation modeling?”. In other words, can R handle everything we throw at it for simulation modeling? Low level functions, high level functions, GIS, data wrangling etc…\nAfter years of working with R as a data analysis and manipulation tool, we weren’t convinced that R was fast enough. We realize now that was mostly because of what we see and hear on the internet (e.g., see table in julialang.org). So, we started benchmarking R with a series of low and high level functions. This is part 1 of a multi-part series of posts about this benchmarking experiment with R in the coming weeks.\nThe objective of this experiment is to show some speed comparisons between R and other languages and software, including C++ and GIS software. Clearly this is NOT a comparison between R and, say, C++, because many of the functions in R are written in C++ and are wrapped in R. But, if simple R functions are fast, then we can focus our time on more complex things needed for simulation and science.\nSo, is R fast enough?\nAnswer: R is more than fast enough!\nWe will start with a fairly basic low level function, the “mean”…\n\nMean\nFor the mean, we show two different C++ versions. The R function, mean is somewhat slower (about half, but it does more things than just calculate the mean), but the colMeans(x) and calling the primitives directly with sum(x)/length(x) are as fast or faster than the fastest C++ function we can write.\nx &lt;- runif(1e6)\nx1 = matrix(x, ncol=1)\nm=list()\nbenchmark(m[[1]]&lt;-meanC1(x), m[[2]]&lt;-meanC2(x), m[[3]]&lt;-mean(x), \n                m[[4]]&lt;-mean.default(x), m[[5]]&lt;-sum(x)/length(x), \n                m[[6]]&lt;- .Internal(mean(x)), m[[7]]&lt;-colMeans(x1),\n                replications=2000L, columns=c(\"test\", \"elapsed\", \"relative\"), order=\"relative\")\n##                           test elapsed relative\n## 1          m[[1]] &lt;- meanC1(x)    1.86    1.000\n## 5   m[[5]] &lt;- sum(x)/length(x)    1.90    1.022\n## 7       m[[7]] &lt;- colMeans(x1)    1.94    1.043\n## 4    m[[4]] &lt;- mean.default(x)    3.81    2.048\n## 6 m[[6]] &lt;- .Internal(mean(x))    3.81    2.048\n## 3            m[[3]] &lt;- mean(x)    3.82    2.054\n## 2          m[[2]] &lt;- meanC2(x)   13.42    7.215\n# Test that all did the same thing\nall(sapply(1:6, function(y) all.equal(m[[y]],m[[y+1]])))\n## [1] TRUE\n\nConclusions\nYES! R is more than fast enough. But there is more to come… For the mean, the fastest way to calculate it for sizeable numeric vectors (1e6) is to use sum(x)/length(x), colMeans(x), or the efficient version of the C++ code meanC1. But, it is important to note that even the worst R version is better than an apparently minor coding decision in the second C++ version (meanC2 divides by N every time).\n\n\nNext time\nWe will redo the Fibonacci series, a common low level benchmarking test that shows R to be slow. But it turns out to be a case of bad coding…\n\n\nTake home message\nThe take home messages for the whole exercise are these:\n\nbuilt-in R functions (written in R or C++ or any other language) are often faster than ad hoc C++ functions, particularly if they are built with speed in mind (like colMeans).\nmost built-in R functions must to be used in a vectorized way to achieve these speeds, avoiding loops unless it is strictly necessary to keep the sequence (though see the data.table package)\nthere are often different ways to do the same thing in R; some are much faster than others (see following weeks posts). Use the Primitives where possible (names(methods:::.BasicFunsList))\n\n\n\n\nFunctions used\nThe C++ functions that were used are:\ncppFunction('double meanC1(NumericVector x) {\n  int n = x.size();\n  double total = 0;\n\n  for(int i = 0; i &lt; n; ++i) {\n    total += x[i];\n  }\n  return total / n;\n}')\n\n# inefficient because the /n is done within the loop\ncppFunction('double meanC2(NumericVector x) {\n  int n = x.size();\n  double y = 0;\n\n  for(int i = 0; i &lt; n; ++i) {\n    y += x[i] / n;\n  }\n  return y;\n}')\n\n\nSystem used:\nTests were done on an HP Z400, Xeon 3.33 GHz processor, running Windows 7 Enterprise, using:\n## R version 3.2.0 (2015-04-16)\n## Platform: x86_64-w64-mingw32/x64 (64-bit)\n## Running under: Windows 7 x64 (build 7601) Service Pack 1\n## \n## locale:\n## [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252   \n## [3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C                   \n## [5] LC_TIME=English_Canada.1252    \n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets  methods   base     \n## \n## other attached packages:\n## [1] Rcpp_0.11.5      rbenchmark_1.0.0\n## \n## loaded via a namespace (and not attached):\n## [1] formatR_1.1     tools_3.2.0     htmltools_0.2.6 yaml_2.1.13    \n## [5] rmarkdown_0.5.1 knitr_1.9       stringr_0.6.2   digest_0.6.8   \n## [9] evaluate_0.6"
  },
  {
    "objectID": "posts/2015-09-04-Is-R-fast-enough-04.html",
    "href": "posts/2015-09-04-Is-R-fast-enough-04.html",
    "title": "Is R Fast Enough? - Part 4 - ‘Loops’",
    "section": "",
    "text": "In part 4 of this series on benchmarking R, we’ll explore loops and a common alternative, vectorizing. This is probably the “biggest” issue making people think that R is a slow language. Essentially, other procedural languages use explicit loops; programmers moving from those languages to R start with the same procedures and find that R is slow. We will discuss a range of ways making loops faster and how vectorizing can help.\nThere are many other resources about this topic; we will try to be concise and show the worst case, the best case, and many little steps in between."
  },
  {
    "objectID": "posts/2015-09-04-Is-R-fast-enough-04.html#loops",
    "href": "posts/2015-09-04-Is-R-fast-enough-04.html#loops",
    "title": "Is R Fast Enough? - Part 4 - ‘Loops’",
    "section": "Loops",
    "text": "Loops\nLoops have been the achilles heel of R in the past. In version 3.1 and forward, much of this problem appears to be gone. As could be seen in the Fibonacci example, pre-allocating a vector and filling it up inside a loop can now be very fast and efficient in native R. To demonstrate these points, below are 6 ways to achieve the same result in R, beginning with a naive loop approach, and working up to the fully vectorized approach. I am using a very fast vectorized function, seq_len, to emphasize the differences between using loops and optimized vectorized functions.\nThe basic code below generates random numbers. The sequence goes from a fully unvectorized, looped structure, with no pre-allocation of the output vector, through to pure vectorized code. The intermediate steps are:\n\nLoop\nLoop with pre-allocated length of output\nsapply (like loops)\nsapply with pipe operator\nvectorized\nvectorized with no intermediate objects\nC++ vectorized\n\nlibrary(magrittr) # for pipe %&gt;%\nlibrary(data.table)\nN = 1e5\n\nunifs &lt;- runif(N) \ndt = data.table(num=rep(NA_real_, N))\n\nmb = microbenchmark::microbenchmark(times=5L,\n\n  # no pre-allocating of vector length, generating uniform random numbers once,\n  # then calling them within each loop\n  loopWithNoPreallocate = {\n    set.seed(104)\n    a &lt;- numeric()\n      for (i in 1:N) {\n        a[i] = unifs[i]\n      } \n     a\n  },\n  \n  # pre-allocating vector length, generating uniform random numbers once,\n  # then calling them within each loop\n  loopWithPreallocate = {\n      set.seed(104)\n      a &lt;- numeric(N) \n      for (i in 1:N) {\n        a[i] = unifs[i]\n      }\n      a\n  },\n   \n  # sapply - generally faster than loops\n  sapplyVector1 = {\n        set.seed(104)\n        sapply(unifs,function(x) x)\n  },\n  \n  # sapply with pipe operator: no intermediate objects are created\n  sapplyWithPipe = {\n        set.seed(104)\n        unifs &lt;- (runif(N)) %&gt;%\n          sapply(.,function(x) x)\n  },\n  \n  # use data.table set function, which can be very fast inside a loop\n  datatableSet = {\n    set.seed(104)\n    for(i in 1L:N) {\n      set(dt, i, j = 1L, unifs[i])\n    }\n    dt\n  },\n  \n  # vectorized with intermediate object before return\n  vectorizedWithCopy = {\n      set.seed(104)\n      unifs &lt;- runif(N)\n      unifs\n  },\n  \n  # no intermediate object before return\n  vectorizedWithNoCopy = {\n    set.seed(104)\n    runif(N)\n  },\n  \n  cpp = {\n    set.seed(104)\n    runifCpp(N)\n  }\n)\n\nprint(\"Units: milliseconds\")\n## [1] \"Units: milliseconds\"\nsummary(mb, unit=\"ms\")[c(1,2,5,7,8)]\n##                    expr          min       median          max neval\n## 1 loopWithNoPreallocate 12802.511195 12908.986463 13618.461857     5\n## 2   loopWithPreallocate   141.383047   150.713476   199.640091     5\n## 3         sapplyVector1    64.211709    72.396608   104.804129     5\n## 4        sapplyWithPipe    70.540230    74.944790    82.344498     5\n## 5          datatableSet   274.122245   277.530571   286.644428     5\n## 6    vectorizedWithCopy     3.572677     3.702005     3.952369     5\n## 7  vectorizedWithNoCopy     3.729653     3.873727     4.120712     5\n## 8                   cpp     1.437057     1.578675     1.859143     5\n# Test that all results return the same vector\nall.equalV(loopWithNoPreallocate, \n           datatableSet$num, \n           loopWithPreallocate, \n           sapplyVector1, sapplyWithPipe, \n           vectorizedWithCopy, vectorizedWithNoCopy, \n           cpp[,1])\n## Warning in all(sapply(vals[-1], function(x) all.equal(vals[[1]], x))):\n## coercing argument of type 'character' to logical\n## [1] NA\nsumLoops &lt;- round(summary(mb)[[5]],1)\nThe fully vectorized function is 3489x faster than the fully naive loop. Note also that making as few intermediate objects as possible is faster as well. Comparing vectorizedWithCopy and vectorizedWithNoCopy (where the only difference is making one copy of the object) shows virtually no change. This, I believe, is due to some improvements in after version 3.1 of R that reduces copying for vectors and matrices.\nUsing pipes instead of intermediate objects also did not change the speed very much (slight change by -3.34%). Since these are simple tests, larger, or more complex objects, will likely see improvements using pipes.\nNote, in this case, the C++, using Rcpp sugar was the fastest, 2.44x faster.\nNote also, that this example is somewhat artificial, because it is also comparing the random number generating speeds at the same time as the loop speeds. Thus, these benchmarks about loops are simply for illustrative purposes. The speed gains in loops will be determined mostly by what is actually happening within the loops."
  },
  {
    "objectID": "posts/2015-09-04-Is-R-fast-enough-04.html#conclusions",
    "href": "posts/2015-09-04-Is-R-fast-enough-04.html#conclusions",
    "title": "Is R Fast Enough? - Part 4 - ‘Loops’",
    "section": "Conclusions",
    "text": "Conclusions\nWrite vectorized code in R where possible. If not possible, pre-allocate prior to writing loops. If speed is crucial, as in simulation studies using SpaDES, consider writing in C++ via Rcpp package, though as we showed in previous posts, this often is not necessary.\nPerhaps more importantly, with the Rcpp package and its infrastructure, we get access to very fast code, but within the higher level R language opening it up to many more users.\n\nNext time\nWe move on to higher level operations. Specifically, some GIS operations.\n\n\nSee also\nhttps://gallery.rcpp.org/tags/benchmark/\n\n\n\nFunctions used\nall.equalV = function(...) {\n  vals &lt;- list(...)\n  all(sapply(vals[-1], function(x) all.equal(vals[[1]], x)))\n}\n\ncppFunction('NumericMatrix runifCpp(const int N) {\n  NumericMatrix X(N, 1);\n  X(_, 0) = runif(N);\n  return X;\n}')\n\n\nSystem used:\nTests were done on an HP Z400, Xeon 3.33 GHz processor, running Windows 7 Enterprise, using:\n## R version 3.2.2 (2015-08-14)\n## Platform: x86_64-w64-mingw32/x64 (64-bit)\n## Running under: Windows 7 x64 (build 7601) Service Pack 1\n## \n## locale:\n## [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252   \n## [3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C                   \n## [5] LC_TIME=English_Canada.1252    \n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets  methods   base     \n## \n## other attached packages:\n## [1] data.table_1.9.4 magrittr_1.5     Rcpp_0.12.0     \n## \n## loaded via a namespace (and not attached):\n##  [1] knitr_1.9            splines_3.2.2        MASS_7.3-43         \n##  [4] munsell_0.4.2        lattice_0.20-33      colorspace_1.2-6    \n##  [7] multcomp_1.4-1       stringr_1.0.0        plyr_1.8.3          \n## [10] tools_3.2.2          grid_3.2.2           gtable_0.1.2        \n## [13] TH.data_1.0-6        htmltools_0.2.6      survival_2.38-3     \n## [16] yaml_2.1.13          digest_0.6.8         reshape2_1.4.1      \n## [19] ggplot2_1.0.1        formatR_1.1          codetools_0.2-14    \n## [22] microbenchmark_1.4-2 evaluate_0.7         rmarkdown_0.5.1     \n## [25] sandwich_2.3-3       stringi_0.5-5        scales_0.2.5        \n## [28] mvtnorm_1.0-3        chron_2.3-47         zoo_1.7-12          \n## [31] proto_0.3-10"
  },
  {
    "objectID": "posts/2020-08-20-PostDocNorthernEcosystemModeling.html",
    "href": "posts/2020-08-20-PostDocNorthernEcosystemModeling.html",
    "title": "Post-Doc Opportunity In Northern Ecosystem Forecasting",
    "section": "",
    "text": "Northwestern Canada is one of the most rapidly warming regions on Earth. The scale and rapidity of recently observed warming-induced changes indicate that this region is particularly sensitive to climate warming. Unprecedented changes in snow cover and rates of permafrost thaw are transforming ecosystems (e.g., conversion of forests to wetlands; lakes to thaw lake basins; tundra to shrub vegetation), and changing the distribution and routing of water over the landscape, which confounds predictions of ecohydrological responses to warming and changes in precipitation. Altered water flows and sediment regimes have affected the structure and function of streams, rivers, and lakes, including key waterways used for hydropower, water supply, and transportation. These changes directly affect the health, wellbeing, safety and livelihoods of northern communities. As a consequence, government decision makers, Indigenous communities, and co-management boards urgently require science-based predictive tools and user-driven mitigation and adaptation strategies to ensure that “the waters of the Northwest Territories will remain clean, abundant and productive for all time”, as envisioned in the NWT Water Stewardship Strategy.\nWe are seeking a quantitative ecologist/modeler to participate in a large, collaborative project on northern ecosystem dynamics under changing climate. In partnership with academics and several government agencies, the goal of this multi-year research program is to forecast the dynamics of below- and aboveground processes under the anticipated changes coming with climate, natural disturbance, and positive and negative feedbacks. This specific project involves developing forecasting models that couple simulation and statistical models of thermokarst vulnerability, landcover change, above- and below-ground carbon dynamics, and fire dynamics under changing climate. The models will become part of a rich network of models that are compatible with the open R/SpaDES framework (spades.predictiveecology.org). This will enable us to answer multi-faceted questions related to ecosystem change and land management by Indigenous groups, territorial and federal governments, as well as evaluation of other connected issues such as protected areas and species at risk. The new contributions made here will contribute to a general and flexible suite of independent forecasting models that will be configured to meet the emerging needs of our research team, the scientific community and land management pressures in the North. The successful candidate will work with a team of landscape scientists, northern scientists, R programmers and quantitative ecologists to forecast the direct and indirect consequences of climate change on thermokarst, above- and below-ground carbon, natural disturbances, and vegetation dynamics.\nQualifications:\n\nPh.D. in ecology, natural resource sciences, applied mathematics, computer science, statistics, or a related field;\nEvidence of publishing in peer reviewed literature;\nExperience with modeling of vegetation, soils, hydrology, or permafrost;\nHigh-level programming skills (e.g., R or Python);\nExperience with statistical modelling;\nExperience with spatial simulation modelling an asset;\nExperience with Geographic Information Systems and remotely sensed data an asset;\nAble to confidently interact with people of varying backgrounds;\nExperience with climate change projections an asset.\n\nThe direct supervisor will be Eliot McIntire (Pacific Forestry Centre, expertise in applied ecology, conservation and forecasting ecosystems and species) with Jenn Baltzer and Steve Cumming as remote co-supervisors. Additional collaborators on this Northern Water Futures and GNWT Cumulative Impacts Monitoring Project-funded project will include Merritt Turetsky and Kathe Todd-Brown and other post-doctoral fellows and graduate students. The successful candidate will also become part of the Predictive Ecology lab, providing and benefitting from technical support within the group.\nLocation of tenure: The postdoctoral fellow will be administered as a postdoctoral fellow at the University of British Columbia, Vancouver, BC. The position will be physically located in Victoria, British Columbia, Canada, at the Pacific Forestry Centre. There will be opportunities for one or more extended visits to the other labs in the larger project (Baltzer Lab at Wilfrid Laurier University, Waterloo, Ontario and/or Cumming Lab at Laval University, Quebec City) to work with collaborators. Field work is not a principle objective of this position, however, there will be opportunities if desired. Given the current reality of COVID-19, alternative physical locations can be discussed.\nStart date, duration, & compensation: The 2-year position will ideally start in Sept 2020 or as soon after that as possible. The annual salary is $53,000 plus benefits. There will be $5000 for travel, publications, and conferences per year.\nTo Apply: Please provide a letter of interest, your CV, and an example of your writing skills in the form of a peer-reviewed manuscript. Your letter should indicate how you meet each of the criteria, and state when you are able to start and when you can relocate to British Columbia. We will accept applications until a suitable candidate is found. Send application packages to: Eliot McIntire, Eliot.McIntire@canada.ca"
  },
  {
    "objectID": "posts/2018-02-06-NetLogoR-now-on-CRAN.html",
    "href": "posts/2018-02-06-NetLogoR-now-on-CRAN.html",
    "title": "New package NetLogoR now on CRAN",
    "section": "",
    "text": "v0.3.1 is now available on CRAN.\nNetLogoR is a R package to help you build raster- and individual-based models in the R environment following the framework of NetLogo (Wilenski 1999). This package does not require installation of the original NetLogo software; it is a translation into the R language of the structure and functions of NetLogo. NetLogoR provides you classes to define raster cell (“patches”) and moving individual (“turtles”) objects as well as the R translation of NetLogo functions and other complementary ones to build such models. This package allows you to benefit of the fast and easy coding phase from the highly developed NetLogo structure and functions, coupled with the versatility and speed of the R software. The use of the SpaDES package complements well NetLogoR by providing useful functions, such as for model visualization.\nFor a complete list of changes, see the package’s NEWS file."
  },
  {
    "objectID": "posts/2018-02-06-NetLogoR-now-on-CRAN.html#installation",
    "href": "posts/2018-02-06-NetLogoR-now-on-CRAN.html#installation",
    "title": "New package NetLogoR now on CRAN",
    "section": "Installation",
    "text": "Installation\nInstall development libraries: building packages from source requires the appropriate development libraries for your operating system.\n\nWindows: install Rtools.\nmacOS: install Xcode commandline tools from the terminal: xcode-select install.\nDebian/Ubuntu Linux: ensure r-base-dev is installed.\n\nSee here for more details.\n\nCurrent stable release\nInstall from CRAN:\ninstall.packages(\"NetLogoR\")\nInstall from GitHub:\n#install.packages(\"devtools\")\nlibrary(\"devtools\")\ninstall_github(\"PredictiveEcology/NetLogoR\", dependencies = TRUE) # stable\n\n\nDevelopment version (unstable)\nInstall from GitHub:\n#install.packages(\"devtools\")\nlibrary(\"devtools\")\ninstall_github(\"PredictiveEcology/NetLogoR\", ref = \"development\", dependencies = TRUE) # unstable"
  },
  {
    "objectID": "posts/2018-02-06-NetLogoR-now-on-CRAN.html#reporting-bugs",
    "href": "posts/2018-02-06-NetLogoR-now-on-CRAN.html#reporting-bugs",
    "title": "New package NetLogoR now on CRAN",
    "section": "Reporting bugs",
    "text": "Reporting bugs\nBug reports should be reported via the package’s GitHub site:\nhttps://github.com/PredictiveEcology/NetLogoR/issues"
  },
  {
    "objectID": "posts/2015-09-01-fpCompare-0-2-1.html",
    "href": "posts/2015-09-01-fpCompare-0-2-1.html",
    "title": "fpCompare version 0.2.1 released",
    "section": "",
    "text": "Version 0.2.1 of fpCompare has been released on CRAN"
  },
  {
    "objectID": "posts/2015-09-01-fpCompare-0-2-1.html#changes",
    "href": "posts/2015-09-01-fpCompare-0-2-1.html#changes",
    "title": "fpCompare version 0.2.1 released",
    "section": "Changes",
    "text": "Changes\nThis is a maintenance release, with no major changes.\n\nupdate maintainer’s email address\nuse HTTPS for CRAN urls\nimproved vignette formatting (use rmarkdown::render)"
  },
  {
    "objectID": "posts/2015-09-01-fpCompare-0-2-1.html#installation",
    "href": "posts/2015-09-01-fpCompare-0-2-1.html#installation",
    "title": "fpCompare version 0.2.1 released",
    "section": "Installation",
    "text": "Installation\n\nFrom CRAN\ninstall.packages(\"fpCompare\")\n\n\nFrom GitHub\nlibrary(devtools)\ninstall_github(\"PredictiveEcology/fpCompare\")"
  },
  {
    "objectID": "posts/2015-09-01-fpCompare-0-2-1.html#bug-reports",
    "href": "posts/2015-09-01-fpCompare-0-2-1.html#bug-reports",
    "title": "fpCompare version 0.2.1 released",
    "section": "Bug Reports",
    "text": "Bug Reports\nhttps://github.com/PredictiveEcology/fpCompare/issues"
  },
  {
    "objectID": "posts/2016-04-18-SpaDES-v1.1.3-now-on-CRAN.html",
    "href": "posts/2016-04-18-SpaDES-v1.1.3-now-on-CRAN.html",
    "title": "SpaDES v1.1.3 now on CRAN",
    "section": "",
    "text": "v1.1.3 is now available on CRAN!\nThis release fixes a number of bugs that had crept through last week’s 1.1.2 release.\nThe main additions are:\nFor a complete list of changes, see the package’s NEWS file."
  },
  {
    "objectID": "posts/2016-04-18-SpaDES-v1.1.3-now-on-CRAN.html#getting-started-with-spades",
    "href": "posts/2016-04-18-SpaDES-v1.1.3-now-on-CRAN.html#getting-started-with-spades",
    "title": "SpaDES v1.1.3 now on CRAN",
    "section": "Getting started with SpaDES",
    "text": "Getting started with SpaDES\n\nInstallation\n# install `SpaDES` from CRAN\ninstall.packages(\"SpaDES\")\n\n\n# install suggested package `fastshp`\n#  (requires development tools, e.g., Rtools)\ninstall.packages(\"fastshp\", repos = \"https://rforge.net\", type = \"source\")\n\n\nDocumentation\nVignettes:\nAvailable at the wiki as well as in your R session:\nbrowseVignettes(package=\"SpaDES\")\nWebsite:\nhttps://SpaDES.PredictiveEcology.org\nWiki:\nhttps://github.com/PredictiveEcology/SpaDES/wiki"
  },
  {
    "objectID": "posts/2016-04-18-SpaDES-v1.1.3-now-on-CRAN.html#reporting-bugs",
    "href": "posts/2016-04-18-SpaDES-v1.1.3-now-on-CRAN.html#reporting-bugs",
    "title": "SpaDES v1.1.3 now on CRAN",
    "section": "Reporting bugs",
    "text": "Reporting bugs\nContact us via the package GitHub site: https://github.com/PredictiveEcology/SpaDES/issues."
  },
  {
    "objectID": "posts/2016-11-17-Postdoc-Opportunity-Mixed-Severity-Fire-Rocky-Mountains.html",
    "href": "posts/2016-11-17-Postdoc-Opportunity-Mixed-Severity-Fire-Rocky-Mountains.html",
    "title": "Postdoc Opportunity - Mixed Severity Fire Modeling in the Rocky Mountain Foothills (Reposted)",
    "section": "",
    "text": "We are seeking a landscape ecologist or ecological modeller to lead the development of a mixed severity fire regime simulation model that will permit spatial forecasting of forest structure and composition over the 21st century, and backcasting over the past several centuries. The intended applications are to integrated land and forest management on a multi-use landscape of roughly 1,000,000 ha in the foothills of southern Alberta, Canada. There is also an important historical component through the Mountain Legacy Project.\nThe work will be conducted as part of a multidisciplinary team, integrating data from many sources and disciplines e.g. dendrochronological studies, historical fire maps, remote sensed vegetation and forest management data. The model is to be developed in SpaDES an R-based system for developing modular, high performance simulation models integrating processes such as vegetation dynamics, natural disturbances, and forest harvesting. The project leads are E. McIntire (UBC/CFS), S. Cumming (U Laval), L. Daniels (UBC), Z. Gedalof (U. Guelph), E.S. Higgs (U. Victoria) and D. Andison (UBC).\nWe offer a 1 year (renewable) Postdoctoral Fellowship at the level of CAD 51,000 per year, plus benefits, with a CAD 4,000 per year research budget. The position will be located at in the McIntire lab at the Pacific Forestry Center, Canadian Forest Service, Victoria, BC, Canada. The position is funded by the Foothills Research Institute’s Healthy Landscapes Program.\n\nQualifications:\n• Experience with spatial simulation modelling, and in the analytical methods used to estimate model parameters from data (e.g. statistical modelling, Pattern Oriented Modelling) • Knowledge of fire ecology and fire regime modelling • High-level R programming skills; knowledge of C++ and Python will be as asset\n• Data management skills • A track record of peer-reviewed publication\n\n\nStart Date:\nAs soon as possible.\n\n\nTo apply:\nApplicants should submit by email a short statement of interest, a sample of their scientific writing, a current CV, and the names of three references.\nEliot McIntire, Adjunct Prof UBC, Research Scientist CFS eliot.mcintire@canada.ca, 1-250-298-2374"
  },
  {
    "objectID": "posts/2015-05-06-Is-R-fast-enough-03.html",
    "href": "posts/2015-05-06-Is-R-fast-enough-03.html",
    "title": "Is R Fast Enough? - Part 3 - ‘Fibonacci’",
    "section": "",
    "text": "In part 3 of this series on benchmarking R, it will be quick. Just the Fibonacci series. This is one that R gets a really bad reputation about. Because it is an iterative function, it can’t be vectorized, which is the usual way that we make R programs fast. Doing explicit loops in R is thought to be slow. So lets look…\nSimilarly, julialang.org showed that Fibonacci series was, again, particularly bad in R. We, again, felt that this was a case of poor R coding, or more accurately, missing the point of whether R was capable or not.\n\nFibonacci Series\nWe run 2 versions of C++, 2 versions of R that we build here, and 1 version within the numbers package from the open source R community.\n# Define two R functions\nfibR1 = function(n) {\n    fib &lt;- numeric(n)\n    fib[1:2] &lt;- c(1, 2)\n    for (k in 3:n) {\n        fib[k] &lt;- fib[k - 1] + fib[k - 2]\n    } \n    return(fib)\n}\nfibR2 = function(n) {\n     if (n &lt; 2) {\n         return(n)\n     } else {\n         return(fibR2(n-1) + fibR2(n-2))\n     }\n}\n\nN = 20L\nmbFib &lt;- microbenchmark(times=200L, \n                    a &lt;- fibonacci(N+1, TRUE)[N+1], \n                    b &lt;- fibCpp1(N+1), \n                    d &lt;- fibCpp2(N+1), \n                    e &lt;- fibR1(N)[N], \n                    f &lt;- fibR2(N+1))\nsummary(mbFib)[c(1,2,5,7)]\n##                                 expr       min     median        max\n## 1 a &lt;- fibonacci(N + 1, TRUE)[N + 1]    47.924    61.9015  16823.625\n## 2                b &lt;- fibCpp1(N + 1)    55.604    60.2115    110.899\n## 3                d &lt;- fibCpp2(N + 1)    55.604    61.4405    128.409\n## 4                   e &lt;- fibR1(N)[N]    35.329    44.8520    980.880\n## 5                  f &lt;- fibR2(N + 1) 85597.578 88614.4030 133390.309\nall.equalV(a,b,d, e, f)\n## [1] TRUE\nHere, one of the two native R implementations is 1599x faster by pre-allocating the output vector size. The fibonacci function in the package numbers was 2.36x slower than the faster R function because it has error checking. The native C++ version was 1.12x slower.\n\nTake home points:\n\nPre-allocate vectors. This is standard in other languages, yet it is not done in many basic tests of R code.\n\nR certainly held its own, again, compared to simple C++ functions precompiled using Rcpp package. In this case, we used native R with pre-allocation, and it was faster than the fastest C++ version. And of course, there was a very slow way to do things in R as well. The function within the package numbers was very fast and had nice checking within the function that is likely worth the overhead in many cases.\n\n\nConclusion\nYES! R is more than fast enough.\n\n\nNext time - Loops\nHow to make loops in R faster, for those times that you can’t make code vectorized.\n\n\n\nFunctions used\nThe C++ functions that were used are:\ncppFunction('int fibCpp2(const int x) {\n    if (x == 0 || x == 1) return(x);\n    return (fibCpp2(x - 1)) + fibCpp2(x - 2);\n}')\n\ncppFunction('int fibCpp1(int n) {\n    return n &lt; 2 ? n : fibCpp1(n-1) + fibCpp1(n-2);\n}')\n\nall.equalV = function(...) {\n  vals &lt;- list(...)\n  all(sapply(vals[-1], function(x) all.equal(vals[[1]], x)))\n}\n\n\nSystem used:\nTests were done on an HP Z400, Xeon 3.33 GHz processor, running Windows 7 Enterprise, using:\n## R version 3.2.0 (2015-04-16)\n## Platform: x86_64-w64-mingw32/x64 (64-bit)\n## Running under: Windows 7 x64 (build 7601) Service Pack 1\n## \n## locale:\n## [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252   \n## [3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C                   \n## [5] LC_TIME=English_Canada.1252    \n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets  methods   base     \n## \n## other attached packages:\n## [1] microbenchmark_1.4-2 numbers_0.5-6        Rcpp_0.11.5         \n## [4] rbenchmark_1.0.0    \n## \n## loaded via a namespace (and not attached):\n##  [1] codetools_0.2-11 digest_0.6.8     MASS_7.3-40      grid_3.2.0      \n##  [5] plyr_1.8.1       gtable_0.1.2     formatR_1.1      scales_0.2.4    \n##  [9] evaluate_0.6     ggplot2_1.0.1    reshape2_1.4.1   rmarkdown_0.5.1 \n## [13] proto_0.3-10     tools_3.2.0      stringr_0.6.2    munsell_0.4.2   \n## [17] yaml_2.1.13      colorspace_1.2-6 htmltools_0.2.6  knitr_1.9"
  },
  {
    "objectID": "posts/2016-03-09-SpaDES_as_a_playground.html",
    "href": "posts/2016-03-09-SpaDES_as_a_playground.html",
    "title": "SpaDES as a playground",
    "section": "",
    "text": "Imagine a neighbourhood where the kids (scientists/ecological modelers) are all playing scattered all over. Some have backyard swings and slides, others don’t. They are having a grand old time running around having fun, living life (i.e., collecting data and publishing science). What we have done is build a new playground structure that is built with modular tubing for the neighbourhood kids to play on (SpaDES). As we start to invite them to play, they check it out… some come and bring with them the their own toys (pre-existing modules) that can be used with the new structure we built (balls, hoops etc.), and others come with just a desire to add more structures (new modules). We provide the tubing, but people realize that clicking the tubing together is actually something they already knew how to do because it is like lego. The new games that are played are bigger, cooler, and more exciting than when the kids were playing alone or in small groups."
  },
  {
    "objectID": "posts/2016-10-07-SpaDES-v1.3.1-now-on-CRAN.html",
    "href": "posts/2016-10-07-SpaDES-v1.3.1-now-on-CRAN.html",
    "title": "SpaDES v1.3.1 now on CRAN",
    "section": "",
    "text": "v1.3.1 is now available on CRAN.\nThis is a fairly significant update, with several important enhancements and bug fixes.\nFor a complete list of changes, see the package’s NEWS file."
  },
  {
    "objectID": "posts/2016-10-07-SpaDES-v1.3.1-now-on-CRAN.html#getting-started-with-spades",
    "href": "posts/2016-10-07-SpaDES-v1.3.1-now-on-CRAN.html#getting-started-with-spades",
    "title": "SpaDES v1.3.1 now on CRAN",
    "section": "Getting started with SpaDES",
    "text": "Getting started with SpaDES\n\nInstallation\n# install `SpaDES` from CRAN\ninstall.packages(\"SpaDES\")\n\n\n# install suggested package `fastshp`\n#  (requires development tools, e.g., Rtools)\ninstall.packages(\"fastshp\", repos = \"https://rforge.net\", type = \"source\")\n\n\nDocumentation\nVignettes:\nAvailable at the wiki as well as in your R session:\nbrowseVignettes(package=\"SpaDES\")\nWebsite:\nhttps://SpaDES.PredictiveEcology.org\nWiki:\nhttps://github.com/PredictiveEcology/SpaDES/wiki"
  },
  {
    "objectID": "posts/2016-10-07-SpaDES-v1.3.1-now-on-CRAN.html#reporting-bugs",
    "href": "posts/2016-10-07-SpaDES-v1.3.1-now-on-CRAN.html#reporting-bugs",
    "title": "SpaDES v1.3.1 now on CRAN",
    "section": "Reporting bugs",
    "text": "Reporting bugs\nContact us via the package GitHub site: https://github.com/PredictiveEcology/SpaDES/issues."
  },
  {
    "objectID": "posts/2018-06-14-managing-large-spades-projects.html",
    "href": "posts/2018-06-14-managing-large-spades-projects.html",
    "title": "Managing large SpaDES projects",
    "section": "",
    "text": "A recent discussion on the SpaDES users forum brought up the question of how to manage projects that rely on multiple SpaDES modules. This question came up in the context of module development, but I’ll offer answers from both a user and developer perspective.\nUPDATE: See the followup post here."
  },
  {
    "objectID": "posts/2018-06-14-managing-large-spades-projects.html#basic-directory-structure",
    "href": "posts/2018-06-14-managing-large-spades-projects.html#basic-directory-structure",
    "title": "Managing large SpaDES projects",
    "section": "Basic directory structure",
    "text": "Basic directory structure\nThe simplest structure is to use a single directory for all project-related components:\nmyProject/\n|_  cache/            # use this for your simulation cachePath\n|_  inputs/           # use this for your simulation inputPath\n|_  manuscripts/\n|_  modules/          # use this for your simulation modulePath\n    |_  module1/\n    |_  module2/\n    |_  module3/\n    |_  module4/\n    |_  module5/\n|_  outputs/          # use this for your simulation outputPath\n...\nMost SpaDES users will get modules via downloadModule(), and should save these modules in the project’s modules/ sub-directory. New modules should also be created in this directory. Remember that each module should be self-contained, and that data are stored in the module’s data/ sub-directory (often downloaded via downloadData())."
  },
  {
    "objectID": "posts/2018-06-14-managing-large-spades-projects.html#version-control",
    "href": "posts/2018-06-14-managing-large-spades-projects.html#version-control",
    "title": "Managing large SpaDES projects",
    "section": "Version control",
    "text": "Version control\n\nSimple module versioning\nEvery module has a version number in its metadata. To download a specific version of a module via downloadModule(), specify the version argument. This should be included in your project’s main script / Rmd file. Every project should be explicit about which versions of the modules it is using.\n\n\nUsing git\nMore advanced users and developers may choose to use more recent or in-development versions of the modules instead of the versions in the SpaDES-modules repository (and accessed via downloadModule()). Many SpaDES module authors/developers use GitHub for version control, so we can get tagged module versions as well as in-development versions of the code. To use version-controlled SpaDES modules in your project, we use git submodules.\nHere, we assume that you are familiar with git (and GitHub) and are also using it for version control of your own project.\nmyProject/            # a version controlled git repo\n|_  .git/\n|_  cache/            # should be .gitignore'd\n|_  inputs/           # should be .gitignore'd (selectively)\n|_  manuscripts/\n|_  modules/\n    |_  module1/      # can be a git submodule\n    |_  module2/      # can be a git submodule\n    |_  module3/      # can be a git submodule\n    |_  module4/      # can be a git submodule\n    |_  module5/      # can be a git submodule\n|_  outputs/          # should be .gitignore'd\n...\nRemember that large data files should not managed using git. Each module’s data directory should have it’s own .gitignore file. These data files should be easily retrieved via download or created by the module.\n\nUsing git submodules\nWe will add each of the SpaDES modules to our project as git submodules via the command line (but GitKraken does support git submodules). (You’ll need to delete the moduleN/ sub-directories within modules.)\ncd ~/Documents/myProject/modules\n\ngit submodule add https://github.com/USERNAMEA/module1\ngit submodule add https://github.com/USERNAMEA/module2\ngit submodule add https://github.com/USERNAMEB/module3\ngit submodule add https://github.com/USERNAMEB/module4\ngit submodule add https://github.com/USERNAMEC/module5\n\ngit push origin master\nNow our directory structure looks like this:\nmyProject/            # (https://github.com/MYUSERNAME/myProject)\n|_  .git/\n|_  cache/            # should be .gitignore'd\n|_  inputs/           # should be .gitignore'd (selectively)\n|_  manuscripts/\n|_  modules/\n    |_  module1/      # git submodule (https://github.com/USERNAMEA/module1)\n    |_  module2/      # git submodule (https://github.com/USERNAMEA/module2)\n    |_  module3/      # git submodule (https://github.com/USERNAMEB/module3)\n    |_  module4/      # git submodule (https://github.com/USERNAMEB/module4)\n    |_  module5/      # git submodule (https://github.com/USERNAMEC/module5)\n|_  outputs/          # should be .gitignore'd\n...\nIn the above example, we are working with 6 different GitHub repositories, one for each SpaDES module plus our myProject repo.\nNow, we manage each of the SpaDES modules (git submodules) independently. Because each of these submodules simply link back to another git repository, we can make changes upstream in the corresponding repo. We then need to pull in these upstream changes to specific modules as follows:\ncd ~/Documents/myProject/modules\n\ngit submodule update --remote module1\nIf we make changes to modules locally and want to push them to the remote we can do so using:\ncd ~/Documents/myProject/modules/module1\n\ngit push\nThis will push only the (committed) changes made to module1."
  },
  {
    "objectID": "posts/2018-06-14-managing-large-spades-projects.html#parent-and-child-modules",
    "href": "posts/2018-06-14-managing-large-spades-projects.html#parent-and-child-modules",
    "title": "Managing large SpaDES projects",
    "section": "Parent and child modules",
    "text": "Parent and child modules\nAnother option (as a developer) to make working with multiple SpaDES modules easier, is to create a parent module that specifies a group of modules as its children. In this way, a user only needs to call downloadModule() or simInit() specifying the parent module name.\nEven though a parent (and grandparent, etc.) module can be thought hierarchically above child modules, remember that from a directory structure standpoint, all modules (child or parent) are at the same level:\nmyProject/            # a version controlled git repo\n|_  .git/\n|_  cache/            # should be .gitignore'd\n|_  inputs/           # should be .gitignore'd (selectively)\n|_  manuscripts/\n|_  modules/\n    |_  parent1/      # with children: modules 1-5\n    |_  module1/\n    |_  module2/\n    |_  module3/\n    |_  module4/\n    |_  module5/\n|_  outputs/          # should be .gitignore'd\n...\nHere, all of these modules (including the parent) can be git modules, and thus managed independently."
  },
  {
    "objectID": "posts/2018-06-14-managing-large-spades-projects.html#summary",
    "href": "posts/2018-06-14-managing-large-spades-projects.html#summary",
    "title": "Managing large SpaDES projects",
    "section": "Summary",
    "text": "Summary\nThe take away here is that when it comes to basic project organization, use a single directory for the project, and organize SpaDES modules within a single sub-directory therein. If you’re using git version control (and you really should be using version control!) then git submodules offer an elegant way to manage dependencies."
  },
  {
    "objectID": "posts/2018-08-16-working-with-modules-and-projects.html",
    "href": "posts/2018-08-16-working-with-modules-and-projects.html",
    "title": "Working with SpaDES modules and Rstudio projects",
    "section": "",
    "text": "A previous post discussed how to manage large SpaDES projects, and suggested the following project directory structure:\nmyProject/            # a version controlled git repo\n  |_  .git/\n  |_  cache/            # should be .gitignore'd\n  |_  inputs/           # should be .gitignore'd (selectively)\n  |_  manuscripts/\n  |_  modules/\n    |_  module1/      # can be a git submodule\n    |_  module2/      # can be a git submodule\n    |_  module3/      # can be a git submodule\n    |_  module4/      # can be a git submodule\n    |_  module5/      # can be a git submodule\n  |_  outputs/          # should be .gitignore'd\n  ...\nThe layout of a project directory is somewhat flexible, but this approach works especially well if you’re a module developer using git submodules for each of your module subdirectories. And each module really should be its own git repository:\n\npeople don’t need to pull everything in just to work on a single module;\nmakes it possible to use git submodules for [Rstudio] projects;\neasy to setup additional SpaDES module repositoriess.\n\nHowever, note that you cannot nest a git repository inside another git repository. So if you are using git for your project directory, you cannot use SpaDES modules as repos inside that project directory (this is what git submodules are for). If git submodules aren’t your thing, then you will need to keep your project repo separate from your module repo!\nmodules/                # use this for your simulation modulePath\n  |_  module1/\n  |_  module2/\n  |_  module3/\n  |_  module4/\n  |_  module5/\n\nmyProject/\n  |_  cache/            # use this for your simulation cachePath\n  |_  inputs/           # use this for your simulation inputPath\n  |_  manuscripts/\n  |_  outputs/          # use this for your simulation outputPath\n  ...\nAlternatively, your myProject/ directory could be a subdirectory of modules/.\nmodules/                # use this for your simulation modulePath\n  |_  module1/\n  |_  module2/\n  |_  module3/\n  |_  module4/\n  |_  module5/\n  |_  myProject/\n    |_  cache/          # use this for your simulation cachePath\n    |_  inputs/         # use this for your simulation inputPath\n    |_  manuscripts/\n    |_  outputs/        # use this for your simulation outputPath\n  ...\nThese allow you to have each module and project be a git repository, and if you’re worried about storage space it ensures you only keep one copy of a module no matter how many projects it’s used with. However, the drawback is that it’s inconsistent with the way Rstudio projects work, because not all project-related files are in the same directory. This means you need to take extra care to ensure that you set your module path using a relative file path (e.g., ../modules), and you’ll need to take even more care to update this path if you move the modules/ directory or are sharing your project code (because your collaborator may store their modules in a different location).\nIn the end, which approach you use will depend on your level of git-savviness (and that of your collaborators), and how comfortable you are using git submodules."
  },
  {
    "objectID": "posts/2015-04-22-new-site.html",
    "href": "posts/2015-04-22-new-site.html",
    "title": "New Webpage",
    "section": "",
    "text": "Welcome! We are starting a new blog about predicting in ecology. There are many topics to cover as we are working through many of them currently. One of the key tools we use is simulation modeling. Please see our R package, SpaDES, for more about that.\nSee you soon!"
  },
  {
    "objectID": "posts/2015-04-24-installing-R-spatial-packages.html",
    "href": "posts/2015-04-24-installing-R-spatial-packages.html",
    "title": "Installing R spatial packages",
    "section": "",
    "text": "This guide will show you how to install a variety of packages used for analyzing spatial data in R. This is tested for R versions 3.1.2, 3.1.3, and 3.2.0; and for the operating systems explicitly mentioned in this guide."
  },
  {
    "objectID": "posts/2015-04-24-installing-R-spatial-packages.html#prerequisites-and-dependencies",
    "href": "posts/2015-04-24-installing-R-spatial-packages.html#prerequisites-and-dependencies",
    "title": "Installing R spatial packages",
    "section": "Prerequisites and dependencies",
    "text": "Prerequisites and dependencies\n\nWindows 7\nMost R packages that require additional software will come with their own versions of that software. This generally means that installing R packages on Windows can be easier for the user than for other OSes because you don’t have to explicitly think about additional software dependencies.\n\n\nOSX (Mavericks / Yosemite)\n\nInstall brew\nThis simple one-liner install is from the brew homepage, brew.sh.\nruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"\nAdd the science formulae:\nbrew tap homebrew/science\n\n\nUpgrade existing brew installation\nbrew update && brew upgrade\n\n\nInstall additional components\nbrew install gdal\nbrew install homebrew/science/netcdf\n\n\n\nLinux (Debian 7 / Ubuntu 14.04)\nSome of the R packages that require additional system packages come prebuilt as r-cran-PACKAGE. However, this precompiled version make not always be the most recent, so building it yourself is often best. For the R packages we’ll be installing, we require the following system packages:\n### install the system dependencies for spatial packages\nsudo apt-get build-dep r-cran-rgl r-cran-tkrplot\nsudo apt-get install bwidget libgdal-dev libgdal1-dev libgeos-dev libgeos++-dev libgsl0-dev libproj-dev libspatialite-dev netcdf-bin\n\n### on machines not running a desktop environment (e.g., a server you SSH into):\n# Install the X virtual frame buffer:\nsudo apt-get install xauth xfonts-base xvfb\n\n# Start each R session using xvfb to avoid warnings about no DISPLAY being set:\nxvfb-run R\n\n### Install additional useful system dependencies\nsudo apt-get install ca-certificates curl libxml2-dev"
  },
  {
    "objectID": "posts/2015-04-24-installing-R-spatial-packages.html#r-package-installation",
    "href": "posts/2015-04-24-installing-R-spatial-packages.html#r-package-installation",
    "title": "Installing R spatial packages",
    "section": "R package installation",
    "text": "R package installation\n### install `devtools`\ninstall.packages(\"devtools\")\n\n### install the main spatial packages we use\nspatial.pkgs &lt;- c(\"geoR\", \"mapdata\", \"maps\", \"maptools\", \"RandomFields\", \"plotKML\", \"rgdal\", \"rgeos\", \"shapefiles\", \"sp\", \"spatstat\", \"raster\", \"rts\")\nlapply(spatial.pkgs, install.packages)\n\n### install additional spatial packages\ndevtools::install_github(\"s-u/fastshp\")"
  },
  {
    "objectID": "posts/2022-06-14-post-doc-announcement.html",
    "href": "posts/2022-06-14-post-doc-announcement.html",
    "title": "Research Associate Job: Forecasting land use changes due to resource development to improve boreal caribou conservation",
    "section": "",
    "text": "Northern ecosystems in Canada are changing at a rate twice as fast as other areas of the globe due to climate change. Climate change can result in direct effects on wildlife (higher mortality, lower reproduction) but also indirect effects on their habitat through changes in vegetation (e.g. shifts in tree species composition within forests) and natural disturbances like wildfire (e.g. increase in the frequency and size of fires). In addition to climate change, northern ecosystems are affected by human disturbance primarily associated with resource development that includes: forestry, conventional oil and gas development and extraction, mineral mining, wind power, linear features and road development. Boreal caribou are a species of cultural, economic, and ecological importance in northern regions of Canada. Numerous sources have identified these anthropogenic disturbances as the most important contributor to declines of boreal caribou; yet, forecasting these disturbances, and their interactions with vegetation and natural disturbances under climate change remains a challenge.\nThe Department of Forest Resources Management, UBC-Vancouver campus, seeks a Research Associate to undertake research on forecasting land use changes due to resource development to improve boreal caribou conservation. This research associate will be responsible for undertaking research on a project funded by Cumulative Impact Monitoring Program of the Government of Northwest Territories (NWT CIMP) and supported by Environment and Climate Change Canada and Natural Resources Canada under the supervision of Dr. Eliot McIntire and in collaboration with researchers from ENR/GNWT, the Canadian Forest Service (CFS), ECCC, and the UBC Faculty of Forestry. The overall objective of the position is to develop and implement new models that can forecast the impacts of resource development on boreal caribou resource selection and population demographics in Northwest Territories (NT), Canada. The specific objectives are: (1) to compile resource development potential mapping within the boreal region of Northwest Territories, Canada (NT); (2) to integrate resource development potential mapping with forecasts of vegetation, wildfire, climate, and caribou developed within the boreal regions within NT; and (3) forecast through time (2021-2100) the regional cumulative effects of resource development, vegetation, wildfire, and climate on habitat supply and boreal caribou population demographics by examining resource development scenarios.\nThis project will take advantage of an open modeling framework – SpaDES, developed within the R language – to integrate the novel components created here with existing models (vegetation dynamics, wildfire, caribou resource selection and population growth). Results from this work will help inform current and future cumulative effects on boreal caribou habitat supply and population demography and support caribou range planning and decision making in the NT. The successful candidate will work with a network of landscape scientists, northern scientists, caribou biologists, R programmers, and quantitative ecologists.\n\nRequired qualifications:\n• A PhD in ecology, natural resource sciences, geography, applied mathematics, computer science, statistics, or a related field; • A minimum of 4 years postdoctoral research experience with landscape simulation, wildlife forecasting, and highly integrated projects; • Proven experience with landscape change simulation including forest growth and mortality, and wildfire simulations at large spatial scale (&gt; 1Mi km2) (i.e., publication in peer-reviewed journal); • Proven experience with forecasting of caribou demographics and habitat (i.e., resource selection models, population growth models, etc.); • Knowledge of the current anthropogenic disturbance challenges in the Northern Boreal Forests of Canada, especially in the Northwest Territories; • Proven advanced knowledge of SpaDES and development of SpaDES modules shown in at least one publication as first author in peer-reviewed literature; • High-level programming skills in R (i.e., statistical analysis, model development, GIS and package development); • Proven experience with version control for coding purposes (i.e., GitHub or similar); • Experience managing or co-managing large scale and highly integrated projects; • Good publication record (i.e., peer-reviewed journal articles, including first author publications) in the last 7 years; • Advanced knowledge in GIS applications (including ArcGIS, QGIS and use of open-source GIS packages in R); • Proven experience with climate change projections; • Excellent oral and written communication skills; • Ability to work in a dynamic and diverse large research team; • Ability to work and communicate within a distributed team (e.g., Zulip or Slack); • Ability to work on a project with defined milestones and timelines.\n\n\nPosition Details:\nThe 2-year position will begin as soon as the candidate is available, with immediate start possible. The minimum annual salary, in accordance with UBC HR guidelines, will be set at $ 60,205 plus benefits. The research associate position will be administered at the University of British Columbia, Vancouver, BC. The position will be primarily located in Victoria, British Columbia, Canada, at the Pacific Forestry Centre. There may be opportunities for visits to NT to work with collaborators and engage partners although travel with depend on current COVID-19 public health guidance. Field work is not anticipated.\nApplications should consist of cover letter, CV and contact information of three references. Please direct inquiries to Principal Investigator, Dr. Eliot McIntire by email eliot.mcintire@ubc.ca.\nApplications should be submitted via Workday: JR8063. Deadline for applications is July 21, 2022 at 11:59pm.\nAll appointments are subject to budget availability.\nAs one of the world’s leading universities, the University of British Columbia creates an exceptional learning environment that fosters global citizenship, advances a civil and sustainable society, and supports outstanding research to serve the people of British Columbia, Canada and the world.\nUBC hires on the basis of merit and is committed to employment equity. All qualified persons are encouraged to apply. Equity and diversity are essential to academic excellence. An open and diverse community fosters the inclusion of voices that have been underrepresented or discouraged. We encourage applications from members of groups that have been marginalized on any grounds enumerated under the B.C. Human Rights Code, including sex, sexual orientation, gender identity or expression, racialization, disability, political belief, religion, marital or family status, age, and/or status as a First Nation, Metis, Inuit, or Indigenous person. All qualified candidates are encouraged to apply; however Canadians and permanent residents will be given priority."
  },
  {
    "objectID": "posts/2016-03-09-Translating_the_incompatible.html",
    "href": "posts/2016-03-09-Translating_the_incompatible.html",
    "title": "Translating the incompatible",
    "section": "",
    "text": "Continuing from previous post on modularity, the next issue, of course, is not every module will be compatible out of the box. If we continue with the example from last post, not every growth module will take “stem counts and size by species”. One solution to this is the idea of translator modules."
  },
  {
    "objectID": "posts/2016-03-09-Translating_the_incompatible.html#translator-modules",
    "href": "posts/2016-03-09-Translating_the_incompatible.html#translator-modules",
    "title": "Translating the incompatible",
    "section": "Translator modules",
    "text": "Translator modules\nThese will create 3 situations:\n\nlossy translators\nlossless translators\nincompatible\n\nIn cases where there is no possible translation between data types or formats, then we are out of luck. We won’t fit every model together… We will likely not ever build a set of translators to connect SORTIE with FORECAST. It certainly would be useful as a hypothesis testing exercise to have them compatible, but that is another entry."
  },
  {
    "objectID": "posts/2016-03-09-Translating_the_incompatible.html#lossy",
    "href": "posts/2016-03-09-Translating_the_incompatible.html#lossy",
    "title": "Translating the incompatible",
    "section": "Lossy",
    "text": "Lossy\nAn example of a lossy translator … Lossy is like changing a 37 level forest cover classification to a 7 level forest cover classification. We certainly can in principle write this translation… do we always want to? Well, who knows a priori. For some purposes, it will be ok to lose some detail in the forest cover classification. Can we go from 7 back to 37?\nMaybe… it depends on a bunch of things. We certainly could do it probabilistically… level 3 becomes 5, 12, 15, and 23 with probabilies 0.1, 0.2, 0.3, and 0.4… or we could do a Bayesian version, where the probability is affected by the prior level of that pixel in the 37 level FC classification (assuming we went from 37 to 7 and now are going back to 37). These translations could be data driven, or expert driven or whatever. But, the point is that the translator modules are an easy mechanism to link modules that don’t, on the surface, look like they link.\n\nExamples of lossy\n\nGIS operations\n\nrasterizing a polygon layer\nreprojecting\n\nEcological operations\n\nreclassifying\ndiscretizing a continuous variable"
  },
  {
    "objectID": "posts/2016-03-09-Translating_the_incompatible.html#not-always-symmetrical",
    "href": "posts/2016-03-09-Translating_the_incompatible.html#not-always-symmetrical",
    "title": "Translating the incompatible",
    "section": "Not always symmetrical",
    "text": "Not always symmetrical\nIt is important to note that a translator may be lossy in one direction, but the reverse translation will lossless. In many cases this is ok. Take for example, if there is a vegetation module that is working with a vegetation layer with 37 classes, and a fire module that can only deal with 7 classes, the sequence would go like this:\n\nvegetation module works on a raster data layer with 37 classes\ntranslator translates the 37 to a 7 class layer for input to fire module\nfire module uses the 7 class layer, and converts some of the pixels in the raster to one class (“burned”)\nthe 2nd translator converts the 7 back to the 37 classes but only for pixels that changed because they were burned, but none of the others.\n37 class vegetation stays at 37 classes, with some pixels converted to “burned”\nvegetation module continues on 37 class layer without any loss"
  },
  {
    "objectID": "posts/2016-03-09-Translating_the_incompatible.html#lossless",
    "href": "posts/2016-03-09-Translating_the_incompatible.html#lossless",
    "title": "Translating the incompatible",
    "section": "Lossless",
    "text": "Lossless\nExamples:\n\nChanging units\nsome geographic reprojections\ndata format"
  },
  {
    "objectID": "posts/2016-03-09-Translating_the_incompatible.html#conclusion",
    "href": "posts/2016-03-09-Translating_the_incompatible.html#conclusion",
    "title": "Translating the incompatible",
    "section": "Conclusion",
    "text": "Conclusion\nTranslator modules will be ubiquitous. They facilitate modularity, and let modelers get on with what they are good at: translating ecological knowledge to predictive models."
  },
  {
    "objectID": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html",
    "href": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html",
    "title": "How to start using Compute Canada cluster with R and SpaDES.",
    "section": "",
    "text": "Is your R script taking too long? Do you find yourself rerunning things over and over? Are you using loops or lapply and think that these are slowing you down? In many cases, working with parallel computing in R can help solves these problems. Working on a super computer with 100s or 1000s of nodes can potentially help a lot.\nThese instructions are for Compute Canada super computing network, and specifically, the Grex machine on the WestGrid network, but they should work with some minor modifications for any super computing cluster."
  },
  {
    "objectID": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#create-an-account-on-your-super-computing-network",
    "href": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#create-an-account-on-your-super-computing-network",
    "title": "How to start using Compute Canada cluster with R and SpaDES.",
    "section": "Create an account on your super computing network",
    "text": "Create an account on your super computing network\nFor Compute Canada, that is here."
  },
  {
    "objectID": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#set-up-your-computer",
    "href": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#set-up-your-computer",
    "title": "How to start using Compute Canada cluster with R and SpaDES.",
    "section": "Set up your computer",
    "text": "Set up your computer\nConnect to supercomputer by command line.\n\nWindows – need putty\nPuTTY is the software to make the command-line connection to Westgrid.\n\nDownload PuTTY from https://the.earth.li/~sgtatham/putty/latest/x86/putty.exe\nPut putty.exe somewhere easy (like Desktop or taskbar). It is how you connect to Westgrid.\nOpen PuTTY (double click)\nCreate a new Session:\n\n\n\ntype grex.westgrid.ca in the Host Name box and in the Saved Sessions box\n\nSelect Connection - Data on left side, fill in your user name in Auto-login username near top.\n\nClick Save"
  },
  {
    "objectID": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#connect-using-putty-ssh",
    "href": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#connect-using-putty-ssh",
    "title": "How to start using Compute Canada cluster with R and SpaDES.",
    "section": "Connect using PuTTY / SSH",
    "text": "Connect using PuTTY / SSH\n\nWindows\n\nGo back to Session on left, click Open at bottom.\n\nYou will see something about ssh key, type yes\n\nType your password, Enter\n\nYou should be connected\n\nWhen you want to disconnect, type exit"
  },
  {
    "objectID": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#linux",
    "href": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#linux",
    "title": "How to start using Compute Canada cluster with R and SpaDES.",
    "section": "Linux",
    "text": "Linux\nIt is much easier on Linux because SSH is built in to most distributions.\n##########\nssh -l LOGINNAME grex.westgrid.ca # change LOGINNAME to your login name\n\n\nexit # to disconnect\n##########"
  },
  {
    "objectID": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#connect-to-supercomputer-for-file-transfer",
    "href": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#connect-to-supercomputer-for-file-transfer",
    "title": "How to start using Compute Canada cluster with R and SpaDES.",
    "section": "Connect to supercomputer for file transfer",
    "text": "Connect to supercomputer for file transfer\n\nWindows\nWe will use WinSCP working (Windows Secure CoPy) to transfer files between your machine and Westgrid.\n\nDownload WinSCP\nUnzip somewhere easy to find.\nDouble click on WinSCP.exe\nDo same (approximately) steps as for putty above, though it is easier because the username is on the same page"
  },
  {
    "objectID": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#once-connected",
    "href": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#once-connected",
    "title": "How to start using Compute Canada cluster with R and SpaDES.",
    "section": "Once connected",
    "text": "Once connected\nOnce on to Grex on Westgrid, you need to load R and gdal. The specific ways to do this will vary by machine and cluster. Please contact your cluster administrators, or find the list of software on each machine.\n\n##########\n\nmodule load r/3.2.2\nmodule load gdal/2.1.0\n\n##########\nNow, you need to work with your own files. Either you can manually copy and paste (drag) in WinSCP, or you can use another tool, like GitHub.\nOn Linux machines, ~ is your home directory and is the shorthand for /home/USERNAME/ … so you can do cd ~ to bring you back to your home directory, in case you ever get lost in sub-sub-sub directories\n\nUse a github repository\nHere, the use must change the lines below for their own github repository of interest. The one below is private and so will not work unless you are part of that repository user group. [edited addition] If you need to connect to a private repo, follow these instructions:\nhttps://help.github.com/articles/generating-an-ssh-key/\nOnce you have completed those steps, then you can clone a private repo:\n##########\n\n# Perhaps clone the McIntire-lab repository\nmkdir -p Documents/GitHub/\ncd ~/Documents/GitHub/\ngit clone git@github.com:eliotmcintire/McIntire-lab.git\n\n# Keep it up to date:\ncd ~/Documents/GitHub/McIntire-Lab\ngit pull\n\n##########"
  },
  {
    "objectID": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#start-r",
    "href": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#start-r",
    "title": "How to start using Compute Canada cluster with R and SpaDES.",
    "section": "Start R",
    "text": "Start R\nFrom the prompt, start R\n##########\nR\n##########\nPrepare your R for what you will need, i.e., install some packages. In the case here, we are loading a simulation package, SpaDES, which has a lot of dependencies and can take a while.\n##########\n# From within R, install necessary packages\ninstall.packages(\"devtools\") # choose HTTP #18, then #1. This is because it is an old version of R, specifically 3.2.2  If it is a newer version of R, then you can choose HTTPS\ninstall.packages(\"Rmpi\")\nlibrary(devtools)\ninstall_github(\"PredictiveEcology/SpaDES@development\")\n##########\nYou can work with this interactive session for small testing things. But the connection we have so far is NOT intended for high performance. Please see next step for that."
  },
  {
    "objectID": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#submitting-jobs",
    "href": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#submitting-jobs",
    "title": "How to start using Compute Canada cluster with R and SpaDES.",
    "section": "Submitting jobs",
    "text": "Submitting jobs\nThe R session that we have entered is the “interactive” part of Grex. You can do small stuff here, but not big analyses. To do that, you need to submit “jobs” from the command prompt, NOT inside R.\nYou need a submit file and an R file with your R code. See two files ending with .pbs in McIntire-lab github repo. See example text that could be put in a submission file, here test.pbs\n##########\n\ncd Documents/GitHub/McIntire-lab/ComputeCanada/\nqsub test.pbs\n\n##########\nAt this point, nothing will appear to happen, but you will have submitted jobs to the queue. You should go to the next steps right away to monitor the jobs. If your job is really quick, and the queue accepts it quickly, then there will be no more jobs to monitor, and you will only have any output or error files that your job produced (see below for those.)"
  },
  {
    "objectID": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#monitoring-jobs",
    "href": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#monitoring-jobs",
    "title": "How to start using Compute Canada cluster with R and SpaDES.",
    "section": "Monitoring jobs",
    "text": "Monitoring jobs\nThere are several commands that you can use at the command line to monitor your jobs. qdel will remove tham.\n##########\n\n# to monitor jobs\nqstat -u USERNAME # change this for your user name\nqstat -f 9963747 # change this for your job number, which can be found from previous line\ncheckjob 9963747 # change this for your job number, which can be found from previous lines\n\n# delete\nqdel 9963747 # delete that job\n\n##########"
  },
  {
    "objectID": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#finding-your-output-files-edited-addition",
    "href": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#finding-your-output-files-edited-addition",
    "title": "How to start using Compute Canada cluster with R and SpaDES.",
    "section": "Finding your output files [edited addition]",
    "text": "Finding your output files [edited addition]\nIf your R script saved any files, then those should be in the directory that your Rscript put them it. In addition to those, there should be 2 files in the same folder from which you submitted your job (the qsub statement). They will have the job filename (the qsub file), but with new filename endings. One will be .e something, the other .o something. The .e something will be your “error” file, which may be useful if there are errors. The .o something file will be your any output statements that would have been written to your R console. The something will be your job number."
  },
  {
    "objectID": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#other-commands-in-linux-that-may-be-useful-for-new-to-linux-users",
    "href": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#other-commands-in-linux-that-may-be-useful-for-new-to-linux-users",
    "title": "How to start using Compute Canada cluster with R and SpaDES.",
    "section": "Other commands in Linux that may be useful for new-to-Linux users",
    "text": "Other commands in Linux that may be useful for new-to-Linux users\nThere are many others that you can find on the Westgrid web page, or widely throughout the internet, but these are certain to come in handy.\n##########\n# linux commands that may be useful\nls # list the contents of a directory\nls -l # \nmv filename newFilename # move a file\ncd ~ # change to home\ncd Documents/GitHub #  change to another directory\nrm dist7* # remove all files in the current directory starting with dist7\n  \nnano filename # a simple text editor\n# CTRL-X will exit from that editor, keyboard (not mouse) can be used to do minor edits\n##########"
  },
  {
    "objectID": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#example-qsub-file",
    "href": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#example-qsub-file",
    "title": "How to start using Compute Canada cluster with R and SpaDES.",
    "section": "Example qsub file",
    "text": "Example qsub file\nThere are a few lines that you will generally change. Going through from top to bottom.\n\nGive your submission a name, with #PBS -N SomeNamehere\nEstimate the time it will take your job to complete. Enter it in walltime=HH:MM:SS\nDecide how many processors, here, 100, and how much memory per processor, here 500mb. Can use gb or kb as suffixes, and can’t use decimals, like 1.5gb, instead use 1500mb\nPerhaps have an epilogue script (see version below), so every job will print this\nLoad all modules you need\nHere, we will use MPI, which is a protocol for using multiple processors, which is supported by Westgrid out of the box, so we don’t have to do anything special.\n\n\nNote, using MPI with R, we will use this approach: ask for 1 MPI process, with many processors. Which translates to , mpiexec -n 1 and #PBS -l procs=100\n\n##########\n\n#!/bin/bash\n#PBS -S /bin/bash\n#PBS -N Rmpi-Test2\n#PBS -l walltime=00:25:00\n#PBS -l procs=100,pmem=500mb\n#PBS -r n\n#PBS -l epilogue=/home/USERNAME/epilogue.script\n\nmodule load r/3.2.2\nmodule load gdal/2.1.0\nmodule load geos/3.5.0\n\n# Script for running serial program, diffuse.\n\ncd $PBS_O_WORKDIR # this will change working directory of the mpiexec process to the directory where the qsub statement was made\necho \"Current working directory is `pwd`\"\necho \"Running on hostname `hostname`\"\n\necho \"Starting run at: `date`\"\nmpiexec -n 1 Rscript --vanilla ./test.R\necho \"Program test finished with exit code $? at: `date`\"\n\n##########"
  },
  {
    "objectID": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#running-r-with-mpi",
    "href": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#running-r-with-mpi",
    "title": "How to start using Compute Canada cluster with R and SpaDES.",
    "section": "Running R with MPI",
    "text": "Running R with MPI\nYou will need to make a script that can be called from the submit file. In the above submit file, I called it test.R and it is called on the mpiexec line. An example of an Rscript file is next.\nHere is an example using SpaDES. The key line is to indicate type = MPI as an argument passed to raster::beginCluster(type = \"MPI\") or to parallel::makeCluster(100, type = \"MPI\").\nKey points below, these are specific to WestGrid:\n\nUse scratch directory for processes that require lots of reading and writing to disk; can use the home directory for read write of infrequent things\nThere must be a makeCluster or beginCluster function call, and the number of processes should match the number requested in the submit file submitted via qsub (i.e., in this case 100)\nAlways run stopCluster(ClusterObjName) or endCluster() to clean up.\n\n##########\n\nlibrary(SpaDES)\nlibrary(parallel)\nlibrary(raster)\n\nmoduleDir &lt;- \"~/Documents/GitHub/McIntire-lab/Wolf\"\nscratchDir &lt;- \"/global/scratch/USERNAME\"\n\n### Next section are all things for SpaDES -- can be skipped for more general R use\ntimes &lt;- list(start = 0, end = 14, timeunit = \"year\")\n\nmodules &lt;- list(\"wolfAlps\")\n\npaths &lt;- list(\n  modulePath = moduleDir,\n  cachePath = file.path(scratchDir, \"outputR\", \"cache\"),\n  inputPath = file.path(moduleDir, \"wolfAlps\", \"data\"),\n  outputPath =  file.path(scratchDir, \"outputR\")\n)\n\ninputs &lt;- data.frame(file = c(\"wolves2008.asc\", \"packs2008.asc\",\n                              \"CMR.asc\", \"HabitatSuitability.asc\"))\n\nmySim &lt;- simInit(times = times, #params = list(wolfAlps=parameters),\n                 modules = modules,\n                 inputs = inputs, paths = paths)\n### End of SpaDES specific stuff\n\nN &lt;- 100\n\n# Make the cluster\ncl &lt;- makeCluster(N, type = \"MPI\")\n\n# You may need things loaded in the R slave processes, like libraries. Each of the \n#   slave R processes is a clean R with few or libraries.\nclusterEvalQ(cl = cl, {\n    library(SpaDES)\n}) \n\n# run some function that knows how to \noutSimList &lt;- experiment(copy(mySim), replicates = N, .plotInitialTime = NA, cl = cl) # don't use plotting\n\n# Stop the cluster. You can use the same cluster many times within this script. Only close it after no\n#  longer needed.\nstopCluster(cl)\n\n# save it for accessing later\nsave(outSimList, file = \"outputs/outSimList.rdata\")\n\n##########"
  },
  {
    "objectID": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#possible-mechanism-to-get-files-off-westgrid-via-ftp",
    "href": "posts/2016-07-04-How-to-start-using-a-HPC-cluster.html#possible-mechanism-to-get-files-off-westgrid-via-ftp",
    "title": "How to start using Compute Canada cluster with R and SpaDES.",
    "section": "Possible mechanism to get files off Westgrid via FTP",
    "text": "Possible mechanism to get files off Westgrid via FTP\nBecause file transfer across the internet is slow, it may be worthwhile to set up an automated copy mechanism at the end of a file. This means that if the program is running overnight and finishes at 2am, the copying would start right away.\n##########\n\nlibrary(RCurl)\n# You will have to set User, password and FTPserver manually (it is not what you see here)\nfilename = \"output.rdata\"\nsystem.time(ftpUpload(filename, paste0(\"ftp://ftpUsername:ftpPassword@ftpServer\",filename)))\n\n##########\n\nEpilogue file\nIf you would like to see some extra information from your job, you can write this following to a file, call it epilogue.script and add it to your home directory. This will then be called from the #PBS line that refers to the epilogue.script file (above)\n\n##########\n\n#!/bin/sh\necho \"Epilogue Args:\"\necho \"Job ID: $1\"\necho \"User ID: $2\"\necho \"Group ID: $3\"\necho \"Job Name: $4\"\necho \"Session ID: $5\"\necho \"Resource List: $6\"\necho \"Resources Used: $7\"\necho \"Queue Name: $8\"\necho \"Account String: $9\"\necho \"\"\nexit 0\n\n##########"
  },
  {
    "objectID": "benchmarking.html",
    "href": "benchmarking.html",
    "title": "Benchmarking",
    "section": "",
    "text": "Introduction\nWe started benchmarking R with a series of low and high level functions. The objective of this experiment is to show some speed comparisons between R and other languages and software, including C++ and GIS software. Clearly this is NOT a comparison between R and, say, C++, because many of the functions in R are written in C++ and are wrapped in R. But, if simple R functions are fast, then we can focus our time on more complex things needed for simulation and science.\nSo, is R fast enough?\nAnswer: R is more than fast enough!\n\n\nBenchmarking posts\n\n{% for post in site.tags.benchmark limit: 20 %}\n\n&lt;li&gt;\n     &lt;a href=\"{{ post.url }}\"&gt;{{ post.title }}&lt;/a&gt;\n     &lt;span&gt;({{ post.date | date:\"%Y-%m-%d\" }})&lt;/span&gt;\n&lt;/li&gt;\n&lt;/div&gt;\n{% endfor %}"
  },
  {
    "objectID": "Workshops.html#upcoming-workshops",
    "href": "Workshops.html#upcoming-workshops",
    "title": "Workshops",
    "section": "Upcoming workshops",
    "text": "Upcoming workshops\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\nDate\n\n\n\n\n\n\n\n\n\nReproducible workflows for landscapes with SpaDES and PERFICT\n\n\nA multi-day workshop focusing on learning robust approaches to building reuseable, reproducibe workflows for ecological applications\n\n\nApr 17, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Workshops.html#past-workshops",
    "href": "Workshops.html#past-workshops",
    "title": "Workshops",
    "section": "Past workshops",
    "text": "Past workshops\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\nDate\n\n\nvideo\n\n\n\n\n\n\n\n\n\nSpaDES Workshop at EFI\n\n\nSpades Workshop at EFI\n\n\nApr 15, 2024\n\n\nundefined\n\n\n\n\n\n\nNo matching items\n\n\n\nVideos"
  },
  {
    "objectID": "Workshops.html#pre-covid-workshops",
    "href": "Workshops.html#pre-covid-workshops",
    "title": "Workshops",
    "section": "Pre-COVID workshops",
    "text": "Pre-COVID workshops\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\nDate\n\n\n\n\n\n\n\n\n\nSpaDES training - Pacific Foresty Centre\n\n\nGeneral SpaDES training focusing on module creation\n\n\nJan 15, 2021\n\n\n\n\n\n\n\nSpaDES training - Pacific Foresty Centre\n\n\nGeneral SpaDES training focusing on module creation\n\n\nJan 15, 2019\n\n\n\n\n\n\n\nSpaDES training - Pacific Foresty Centre\n\n\nGeneral SpaDES training focusing on module creation\n\n\nSep 15, 2018\n\n\n\n\n\n\n\nSpaDES training - Pacific Foresty Centre\n\n\nGeneral SpaDES training focusing on module creation\n\n\nMay 15, 2018\n\n\n\n\n\n\n\nSpaDES training - Pacific Foresty Centre\n\n\nGeneral SpaDES training focusing on module creation\n\n\nDec 7, 2016\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Projects.html",
    "href": "Projects.html",
    "title": "Projects that use SpaDES",
    "section": "",
    "text": "This page is still under construction\n\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\nLast-updated\n\n\n\n\n\n\n\n\n\nWestern Boreal Initiative\n\n\nA large project that is addressing climate and cumulative effects on landscapes of the western boreal forests of Canada\n\n\n2024-04-17\n\n\n\n\n\n\n\nCASTOR\n\n\nCastor - Forest and Land Use Simulator\n\n\n2024-04-17\n\n\n\n\n\n\n\nLANDWEB\n\n\nDefine historical NRV conditions at landscape scales across 140 million ha of the western boreal\n\n\n2024-04-17\n\n\n\n\n\n\n\nLandscapes in Motion\n\n\nA study to inform future management and policy in this important region of Alberta.\n\n\n2022-04-17\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Manuals.html",
    "href": "Manuals.html",
    "title": "Manuals",
    "section": "",
    "text": "Title\n\n\nDescription\n\n\n\n\n\n\n\n\n\nLandR Manual\n\n\nManual for using the LandR ecosystem of modules\n\n\n\n\n\n\n\nLandWeb Manual\n\n\nThe LandWeb project\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "This list is currently only for Eliot McIntire. To see other members’ publications, see AlexChubaty, Yong Luo, AlanaClason, Sarah Bauduin, Jean Marchal, Sébastien Renard, Ceres Barros"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Predictive Ecology Community",
    "section": "",
    "text": "This site assembles an up to date collection of contributors to Predictive Ecology, primarily through the use of SpaDES. We are connected through the common goal of upholding the principles of PERFICT so that we can create a dynamic network of interconnected science modules. The community has active members in Europe and across Canada.\nThe Predictive Ecology Community began in Victoria, British Columbia, Canada, at the Pacific Forestry Centre and at Laval University, Quebec in 2015. Since then, students and postdocs have been primarily at University of British Columbia and Université Laval.\n\nResearchers\n\n\n\n\n\n\n\n\n\n\nDr Eliot McIntire\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDr Alex Chubaty\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDr. Barry Cooke\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDr Céline Boisvenue\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDr Ceres Barros\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDr Frances Stewart\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDr Julie Turner\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDr Steve Cumming\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDr Tati Micheletti\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\nCurrent students/post docs\n\n\n\n\n\n\n\n\n\n\nAna Raymundo\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeneviève Degré-Timmons\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIsolde Lane Shaw\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n\n\n\nResearch Professional\n\n\n\n\n\n\n\n\n\n\nIan Eddy\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n\n\n\nFormer Personnel\n\n\n\n\n\n\n\n\n\n\nDr Alana Clason\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDr. Jean Marchal\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDr Josh Nowak\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMario van Telgen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDr. Sarah Bauduin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSebastien Renard\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDr. Yong Luo\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n\n\nPrior to 2015\n\nÉmilie Tarroux (Post Doctoral Fellow 2015) Facilitation in the boreal forest.\nJulien Beguin (PhD 2013) Caribou, harvesting and fire in the North Shore of Quebec.\nJulia Chacon Labella (PhD - Visiting 2013) Facilitation in semi-arid ecosystems.\nChristian Roy (PhD - 2011) Continental-scale understanding of duck populations.\nPierre Racine (Research Professional 2013) Review of existing modeling platforms\nGhislain Rompré (Post Doctoral Fellow 2009) Modeling endangered butterflies.\nPamela Garcia-Cournoyer (MSc 2010) Harvesting and conservation in Quebec.\nÉmilie Allard (MSc 2009) Understanding deer movement and habitat use in the Upper Laurentian region.\nMelanie Smith (MSc 2008) Spatial goshawk modeling.\nCéline Macabiau (PhD 2009) Spatial population dynamics of spruce grouse in Quebec.\nFrancesca Marucco (PhD 2009) Modeling wolf recolonization in the European Alps. (University of Montana, Supervisor: Dan Pletscher).\nMotoshi Honda (MSc 2008) Hydrology\nAlex Fajardo (Post Doctoral Fellow 2006) Facilitation in Chilean mountain ecosystems.\n\n\n\nCo-op students\n\nTrevor Schiavone (UVic 2015) SpaDES GUI development.\nBrandon Leech (UVic 2015) SpaDES GUI development.\nGreg Zhang (UBC 2015) SpaDES developer.\nAlexander Tso (UBC 2016)\nGreyson Wang (SFU 2015)\nOlivia Sung (UBC 2015)"
  },
  {
    "objectID": "posts/2021-07-14-post-doc-announcement.html",
    "href": "posts/2021-07-14-post-doc-announcement.html",
    "title": "POST-DOC OPPORTUNITY: Forecasting land use changes due to resource development to improve boreal caribou conservation",
    "section": "",
    "text": "Northern ecosystems in Canada are changing at a rate twice as fast as other areas of the globe due to climate change. Climate change can result in direct effects on wildlife (higher mortality, lower reproduction) but also indirect effects on their habitat through changes in vegetation (e.g. shifts in tree species composition within forests) and natural disturbances like wildfire (e.g. increase in the frequency and size of fires). In addition to climate change, northern ecosystems are affected by human disturbance primarily associated with resource development that includes: forestry, conventional oil and gas development and extraction, mineral mining, wind power, linear features and road development. Boreal caribou are a species of cultural, economic, and ecological importance in northern regions of Canada. Numerous sources have identified these anthropogenic disturbances as the most important contributor to declines of boreal caribou; yet, forecasting these disturbances, and their interactions with vegetation and natural disturbances under climate change remains a challenge.\nWe are seeking a quantitative scientist/modeller to develop new models that can forecast the impacts of resource development on boreal caribou resource selection and population demographics in Northwest Territories (NT), Canada. The goals of this multi-year postdoctoral fellowship are to: (1) compile resource development potential mapping within the boreal region of Northwest Territories, Canada (NT); (2) integrate resource development potential mapping with forecasts of vegetation, wildfire, climate, and caribou developed within the boreal regions within NT; and (3) forecast through time (2021-2100) the regional cumulative effects of resource development, vegetation, wildfire, and climate on habitat supply and boreal caribou population demographics by examining resource development scenarios. The fellowship is funded by the Cumulative Impact Monitoring Program of the Government of NT and supported by Environment and Climate Change Canada and Natural Resources Canada. The position will become part of the ongoing Western Boreal Initiative, a large, collaborative project aiming to help with the implementation of the Pan-Canadian Approach to Species-at-Risk Conservation and is a partnership with academics, government agencies, and First Nations. This project will take advantage of an open modeling framework – SpaDES, developed within the R language – to integrate the novel components created here with existing models (vegetation dynamics, wildfire, caribou resource selection and population growth). Results from this work will help inform current and future cumulative effects on boreal caribou habitat supply and population demography and support caribou range planning and decision making in the NT. The successful candidate will work with a network of landscape scientists, northern scientists, caribou biologists, R programmers, and quantitative ecologists.\n\nQualifications:\n\nPh.D. in ecology, natural resource sciences, geography, applied mathematics, computer science, statistics, or a related field;\nEvidence of publishing in peer reviewed literature;\nExperience with modelling of vegetation, soils, hydrology, permafrost, wildfire, or wildlife species;\nHigh-level programming skills (e.g., R or Python);\nExperience with statistical modelling an asset;\nExperience with spatial simulation modelling an asset;\nExperience with Geographic Information Systems and remotely sensed data an asset;\nExperience with climate change projections an asset;\nAble to interact collaboratively with people of varying backgrounds.\n\nThe postdoctoral fellowship will work with Drs. Eliot McIntire (Pacific Forestry Centre, expertise in applied ecology, conservation and forecasting ecosystems and species & UBC), James Hodson (Gov. NT) and C. Lisa Mahon (Environment and Climate Change Canada, U Alberta). Additional collaborators on this project will include Dr. Samuel Hache and Bruce Laurich (Environment and Climate Change Canada), and Drs. Alex Chubaty (FOR-CAST) and Tati Micheletti (UBC) and other post-doctoral fellows and graduate students. The successful candidate will also become part of the Predictive Ecology lab, providing and benefitting from technical support within the group.\n\n\nLocation of tenure\nThe postdoctoral fellow will be administered at the University of British Columbia, Vancouver, BC or through the Canadian Federal Government Postdoctoral programme. The position will be located in Victoria, British Columbia, Canada, at the Pacific Forestry Centre. However, given the current reality of COVID-19, alternative physical locations can be discussed. There may be opportunities for visits to NT to work with collaborators and engage partners although travel with depend on current COVID-19 public health guidance. Field work is not anticipated.\n\n\nStart date, duration, & compensation\nThe 3-year position will begin as soon as the candidate is available, with an ideal start in September 2021. The annual salary is $53,000 plus benefits. There will be $5000 for travel, publications, and conferences per year. As travel restrictions are still uncertain due to COVID-19, the precise details of this will be adjusted according to provincial and federal recommendations.\n\n\nTo Apply\nPlease provide a letter of interest, your CV, and an example of your writing skills in the form of a peer-reviewed manuscript. Your letter should indicate how you meet each of the criteria, and state when you are able to start and when you can relocate to British Columbia. We will start reviewing applications until August 10, 2021 and until a suitable candidate is found. Send application packages to: Eliot McIntire eliot.mcIntire@canada.ca"
  },
  {
    "objectID": "posts/2016-04-20-New-Phd-Position-Caribou-Landscapes-NWT.html",
    "href": "posts/2016-04-20-New-Phd-Position-Caribou-Landscapes-NWT.html",
    "title": "PhD Opportunity in spatial simulation of caribou landscapes in the Northwest Territories.",
    "section": "",
    "text": "As part of a multidisciplinary study of vegetation, fire and permafrost dynamics, the successful applicant will develop spatial simulation models to forecast the abundance and spatial distribution of caribou habitat in relation to climate change, fire and human landuse in the Northwest Territories. The models are to be implemented in SpaDES, a new R package for spatial simulation and individual based modelling. Part of the thesis will involve integration of the team’s research findings, scenario development and the implementation of simulation experiments. However, the student will also be expected to conduct applied research in one related topic (e,g, vegetation dynamics, caribou movement) according to their interest, the results of which would be included as a model component. The qualifications are strong quantitative skills and an interest in spatial simulation independent of disciplinary background. A high level of written communication skills in English is essential. Programming experience (e.g. in R, Python) would be an asset, but modelling courses are available in the lab.\nWe offer a 3yr PhD scholarship at C$23,000/yr. The student will be co-supervised by Steve Cumming, Université Laval, Québec QC and Eliot McIntire, Pacific Forestry Centre, Victoria BC. By preference, the position will be tenable at Laval, with at least one semester as a visiting student at the Pacific Forestry Centre. However, we may be able to accommodate exceptional candidates who prefer to study in Western Canada. There will be opportunities to participate in the 2016 or 2017 summer field season. The position will start September 2016. Applications received before May 9th will receive full consideration.\nThe language of instruction at Université Laval is French, but theses may be written in English. Québec City is well known for its exceptional outdoor recreational opportunities, natural beauty, historical interest and vibrant cultural life. The francophone cultural environment provides non-francophone students an excellent opportunity to develop or improve French language skills\nApplicants should submit by email a short statement of interest, a sample of their scientific writing, a current CV, and the names of three references. For further information, contact the undersigned:\nSteve Cumming, stevec@sbf.ulaval.ca\nDépartement des sciences du bois et de la forêt, Université Laval\nCentre d’étude de la forêt\nEliot McIntire, eliot.mcintire@canada.ca\nPacific Forestry Centre\nVictoria, British Columbia"
  },
  {
    "objectID": "posts/2023-09-08-phd-announcement.html",
    "href": "posts/2023-09-08-phd-announcement.html",
    "title": "PhD position in Ecological Modelling: drought impacts on British Columbia’s forests",
    "section": "",
    "text": "The interior forests of British Columbia (BC) are at particular risk from changes in drought regimes accompanying climate changes. Several tree species in interior BC may already be close to their drought tolerance limits, and further increases in drought intensity and severity could directly and indirectly (via pests, disease and fire) impact tree recruitment, growth and background mortality. This will likely lead to important changes in forest composition and structure, as well as ecosystem services such as carbon retention and timber supply. Despite mounting evidence of drought effects on interior BC forests, the degree to which they will directly and indirectly influence forests and their ecosystem services is unknown across large landscape scales, given the combined stochasticity of drought and non-drought disturbances (e.g. fire) and climate uncertainty.\nWe are looking for a highly motivated enthusiastic and independent person to embark on a 4-year ecological modelling PhD focused on forecasting drought regimes and their impacts on forest dynamics and forest ecosystem services in BC. In particular, the project is aimed at 1) developing a drought effects module for the forest landscape model LandR (Barros et al. 2023 Methods Ecol. Evol.; see also Micheletti et al. 2021 Front. Ecol. Evol.); 2) parameterising direct drought effects on tree species growth and mortality from available empirical data; and 3) simulating forest dynamics under the effects of drought, fire and climate warming and how they translate into changes in ecosystem services.\nCandidates for this position should have:\n\nAn MSc degree in ecology, forestry, environmental sciences or a related field with a strong interest in applied statistics and ecological mechanistic modelling, or an MSc degree in statistics, mathematics, data sciences, or physics with a strong interest in ecological applications\nSolid background knowledge of statistical methods applied to ecological questions\nExperience in programming in R, or a similar programming language (e.g. Python)\nExperience and/or background knowledge of ecological modelling using statistical and mechanistic approaches\nOral and written fluency in English\nAbility to contribute to a positive environment in an inclusive and diverse team\n\nThe position will be based at the University of British Columbia, Vancouver campus, with periods spent at the Ministry of Forests in Victoria.\nIn our team, we strive to create a positive and safe work environment. We believe that diverse backgrounds are essential for academic excellence. We therefore encourage applications from members of underrepresented groups.\nTo apply, please e-mail a one page statement describing your motivation to carry out a PhD project on this topic, a current curriculum vitae, copies of your academic transcripts and contact information for two academic references, using “Application: Ecological Modelling PhD, UBC” as the e-mail subject. Send your e-mail to:\nignacio[dot]barbeito[at]ubc[dot]ca\nceres[dot]barros[at]gov[dot]bc[dot]ca\nThe deadline for applications is September 30th 2023. Start date is flexible and expected to be by no later than May 1st 2024.\nFeel free to send inquiries about this position.\nWhile we thank all candidates for applying, only short-listed candidates will be contacted for interviews."
  },
  {
    "objectID": "posts/2016-11-17-Putting_science_in_the_hands_of_policy_makers.html",
    "href": "posts/2016-11-17-Putting_science_in_the_hands_of_policy_makers.html",
    "title": "Delivering scientific forecasts into the hands of policy makers",
    "section": "",
    "text": "Empirical data have a troublesome way of being both factually true, yet difficult to understand because they exist within a complex web of even more data. Worse, forecasting what the future will look like is an even greater challenge. Scientists have, for a long time, been working on these problems, often with great success, but the venue for reporting is generally peer reviewed journals. In 2014/15, we are now at the point that policy makers must have faster access, and in a context-appropriate way, to utilize the forecasts made by scientists. At CFS, there has been an effort to build integrated systems of communities, of data, and of models. What is still lacking is a delivery mechanism to put those forecasts into the hands of the policy makers."
  },
  {
    "objectID": "posts/2016-11-17-Putting_science_in_the_hands_of_policy_makers.html#certifying-models",
    "href": "posts/2016-11-17-Putting_science_in_the_hands_of_policy_makers.html#certifying-models",
    "title": "Delivering scientific forecasts into the hands of policy makers",
    "section": "Certifying models",
    "text": "Certifying models\nTo maximize the power of such an integrated tool, we, as an organization will have to design a system of “certifying” of operational models. Thus a particular inSpaDES configuration can be given a name (e.g., “The CFS configuration”) because it would have 12 certified CFS models, such as CanFIRE, CBM-CFS3, BioSim etc. Predictions could be relied upon by policy makers, especially when working in conjunction with the relevant scientists."
  },
  {
    "objectID": "posts/2015-04-28-Is-R-fast-enough-02.html",
    "href": "posts/2015-04-28-Is-R-fast-enough-02.html",
    "title": "Is R Fast Enough? - Part 2 - ‘Sorting’",
    "section": "",
    "text": "In part 2 of this series on benchmarking R, we’ll explore sorting. This has been a topic on numerous blogs, discussions and posts around the internet, including here: r-blogger post. Similarly, julialang.org showed that sorting was particularly bad in R. We, again, felt that this was a case of poor R coding, or more accurately, missing the point of whether R was capable or not. Another example here compares R sorting with standard library of C++, called from R.\nIn all cases, we felt that one of the points of using R is that there are concise ways of doing things because the open source community has brought them to R. So lets take advantage of that! We will cover both real number sorting and integer sorting.\n\nSorting\nThis was in part inspired from a blog post by Wingfeet at https://www.r-bloggers.com/quicksort-speed-just-in-time-compiling-and-vectorizing/ which drew on benchmark tests here: https://julialang.org/ Essentially, that julia test was a benchmark to test the speed of Julia. It showed for the Quicksort, that R is 524x slower than C. Below is that version. But, there was no explicit comparison of how the base R sort would match with C, nor how any of the more recent packages with sorting capability fare against these procedural versions of low level languages.\n\nReal number sorting\nx = runif(1e5)\nxtbl &lt;- tbl_df(data.frame(x=x))\n(mbReal &lt;- benchmark(\n           a &lt;- qsort(x), \n           d &lt;- sort(x), \n           e &lt;- sort(x, method=\"quick\"),\n           f &lt;- .Internal(sort(x,decreasing = FALSE)),\n           g &lt;- data.table(x=x,key=\"x\"), \n           h &lt;- arrange(xtbl,x),\n           i &lt;- stl_sort(x),\n           replications=25L, columns=c(\"test\", \"elapsed\", \"relative\"),\n           order=\"relative\"))\n##                                          test elapsed relative\n## 7                            i &lt;- stl_sort(x)    0.19    1.000\n## 5           g &lt;- data.table(x = x, key = \"x\")    0.21    1.105\n## 3              e &lt;- sort(x, method = \"quick\")    0.22    1.158\n## 4 f &lt;- .Internal(sort(x, decreasing = FALSE))    0.26    1.368\n## 2                                d &lt;- sort(x)    0.28    1.474\n## 6                       h &lt;- arrange(xtbl, x)    1.48    7.789\n## 1                               a &lt;- qsort(x)   86.58  455.684\nall.equalV(a, d, e, f, g$x, h$x, i)\n## [1] TRUE\n\n\nInteger sorting\nx = sample(1e6,size = 1e5)\nxtbl &lt;- tbl_df(data.frame(x=x))\n(mbInteger &lt;- benchmark(\n           a &lt;- qsort(x), \n           d &lt;- sort(x), \n           e &lt;- sort(x, method=\"quick\"), \n           f &lt;- .Internal(sort(x,decreasing = FALSE)),\n           g &lt;- data.table(x=x,key=\"x\"), h&lt;-arrange(xtbl,x),\n           i &lt;- stl_sort(x),\n           replications=25L, columns=c(\"test\", \"elapsed\", \"relative\"),\n           order=\"relative\"))\n##                                          test elapsed relative\n## 5           g &lt;- data.table(x = x, key = \"x\")    0.13    1.000\n## 3              e &lt;- sort(x, method = \"quick\")    0.17    1.308\n## 7                            i &lt;- stl_sort(x)    0.19    1.462\n## 4 f &lt;- .Internal(sort(x, decreasing = FALSE))    0.23    1.769\n## 2                                d &lt;- sort(x)    0.25    1.923\n## 6                       h &lt;- arrange(xtbl, x)    0.67    5.154\n## 1                               a &lt;- qsort(x)   89.28  686.769\nall.equalV(a, d, e, f, g$x, h$x, i)\n## [1] TRUE\nBoth real numbers and integers can be sorted quickly with R. The slowest function is indeed the procedural qsort written in native R without any optimization. This was also the qsort that the Julia testers used. Our numbers match almost exactly those from the the table in julialang.org; however, here we also test the real world R usage that a normal R user would face (i.e., we can all use sort()). We show that R competes quite favourably and regularly outperforms standard library of C++ (and Julia!, though that is not tested here explicitly).\n\n\nTake home points:\n\nthe basic R sorting functions are fast. The sort(method=\"quick\") is about as fast as the standard C++ library sort (11% faster).\nusing data.table on integers is 32% faster than the C++ standard library sort.\n\nIn real world situations, where we want to use the easiest, shortest code to produce fast, accurate results, R certainly holds its own compared to the standard C++ library. But of course, there are many ways to do things in R. Some are much faster than others.\n\n\nConclusion\nUsing the sort(method=\"quick\") and data.table sorting, we were able to sort a vector of real numbers 412x faster than a naive procedural coding (qsort) and 687x faster on a vector of integers. These put the data.table sort as fast as or substantially faster than C or Fortran or Julia’s version of quicksort (based on timings on julialang.org).\nYES! R is more than fast enough.\n\n\nNext time (really! I promised it last time…)\nWe will redo the Fibonacci series, a common low level benchmarking test that shows R to be slow. But it turns out to be a case of bad coding…\n\n\n\nFunctions used\nThe C++ functions that were used are:\ncppFunction('NumericVector stl_sort(NumericVector x) {\n   NumericVector y = clone(x);\n   std::sort(y.begin(), y.end());\n   return y;\n}')\nqsort = function(a) {\n    qsort_kernel = function(lo, hi) {\n        i = lo\n        j = hi\n        while (i &lt; hi) {\n            pivot = a[floor((lo+hi)/2)]\n            while (i &lt;= j) {\n                while (a[i] &lt; pivot) i = i + 1\n                while (a[j] &gt; pivot) j = j - 1\n                if (i &lt;= j) {\n                    t = a[i]\n                    a[i] &lt;&lt;- a[j]\n                    a[j] &lt;&lt;- t\n                    i = i + 1;\n                    j = j - 1;\n                }\n            }\n            if (lo &lt; j) qsort_kernel(lo, j)\n            lo = i\n            j = hi\n        }\n    }\n    qsort_kernel(1, length(a))\n    return(a)\n}\n\nall.equalV = function(...) {\n  vals &lt;- list(...)\n  all(sapply(vals[-1], function(x) all.equal(vals[[1]], x)))\n}\n\n\nSystem used:\nTests were done on an HP Z400, Xeon 3.33 GHz processor, running Windows 7 Enterprise, using:\n## R version 3.2.0 (2015-04-16)\n## Platform: x86_64-w64-mingw32/x64 (64-bit)\n## Running under: Windows 7 x64 (build 7601) Service Pack 1\n## \n## locale:\n## [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252   \n## [3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C                   \n## [5] LC_TIME=English_Canada.1252    \n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets  methods   base     \n## \n## other attached packages:\n## [1] data.table_1.9.4 Rcpp_0.11.5      dplyr_0.4.1      rbenchmark_1.0.0\n## \n## loaded via a namespace (and not attached):\n##  [1] digest_0.6.8    assertthat_0.1  chron_2.3-45    plyr_1.8.1     \n##  [5] DBI_0.3.1       formatR_1.0     magrittr_1.5    evaluate_0.5.5 \n##  [9] lazyeval_0.1.10 reshape2_1.4.1  rmarkdown_0.5.1 tools_3.2.0    \n## [13] stringr_0.6.2   yaml_2.1.13     parallel_3.2.0  htmltools_0.2.6\n## [17] knitr_1.9"
  },
  {
    "objectID": "posts/2016-04-20-SpaDES-v1.1.4-now-on-CRAN.html",
    "href": "posts/2016-04-20-SpaDES-v1.1.4-now-on-CRAN.html",
    "title": "SpaDES v1.1.4 now on CRAN",
    "section": "",
    "text": "v1.1.4 is now available on CRAN!\nThis release fixes a bug that cause CRAN check errors in OSX builds.\nFor a complete list of changes, see the package’s NEWS file."
  },
  {
    "objectID": "posts/2016-04-20-SpaDES-v1.1.4-now-on-CRAN.html#getting-started-with-spades",
    "href": "posts/2016-04-20-SpaDES-v1.1.4-now-on-CRAN.html#getting-started-with-spades",
    "title": "SpaDES v1.1.4 now on CRAN",
    "section": "Getting started with SpaDES",
    "text": "Getting started with SpaDES\n\nInstallation\n# install `SpaDES` from CRAN\ninstall.packages(\"SpaDES\")\n\n\n# install suggested package `fastshp`\n#  (requires development tools, e.g., Rtools)\ninstall.packages(\"fastshp\", repos = \"https://rforge.net\", type = \"source\")\n\n\nDocumentation\nVignettes:\nAvailable at the wiki as well as in your R session:\nbrowseVignettes(package=\"SpaDES\")\nWebsite:\nhttps://SpaDES.PredictiveEcology.org\nWiki:\nhttps://github.com/PredictiveEcology/SpaDES/wiki"
  },
  {
    "objectID": "posts/2016-04-20-SpaDES-v1.1.4-now-on-CRAN.html#reporting-bugs",
    "href": "posts/2016-04-20-SpaDES-v1.1.4-now-on-CRAN.html#reporting-bugs",
    "title": "SpaDES v1.1.4 now on CRAN",
    "section": "Reporting bugs",
    "text": "Reporting bugs\nContact us via the package GitHub site: https://github.com/PredictiveEcology/SpaDES/issues."
  },
  {
    "objectID": "posts/2016-02-16-SpaDES-v1.1.1-now-on-CRAN.html",
    "href": "posts/2016-02-16-SpaDES-v1.1.1-now-on-CRAN.html",
    "title": "SpaDES v1.1.1 now on CRAN",
    "section": "",
    "text": "v1.1.1 is now available on CRAN!\nThis release fixes an issue caused by a recent change in the archivist package, and improves module coverage testing.\nFor a complete list of changes, see the package’s NEWS file."
  },
  {
    "objectID": "posts/2016-02-16-SpaDES-v1.1.1-now-on-CRAN.html#getting-started-with-spades",
    "href": "posts/2016-02-16-SpaDES-v1.1.1-now-on-CRAN.html#getting-started-with-spades",
    "title": "SpaDES v1.1.1 now on CRAN",
    "section": "Getting started with SpaDES",
    "text": "Getting started with SpaDES\n\nInstallation\n# install `SpaDES` from CRAN\ninstall.packages(\"SpaDES\")\n\n\n# install suggested package `fastshp`\n#  (requires development tools, e.g., Rtools)\ninstall.packages(\"fastshp\", repos = \"https://rforge.net\", type = \"source\")\n\n\nDocumentation\nVignettes:\nAvailable at the wiki as well as in your R session:\nbrowseVignettes(package=\"SpaDES\")\nWebsite:\nhttps://SpaDES.PredictiveEcology.org\nWiki:\nhttps://github.com/PredictiveEcology/SpaDES/wiki"
  },
  {
    "objectID": "posts/2016-02-16-SpaDES-v1.1.1-now-on-CRAN.html#reporting-bugs",
    "href": "posts/2016-02-16-SpaDES-v1.1.1-now-on-CRAN.html#reporting-bugs",
    "title": "SpaDES v1.1.1 now on CRAN",
    "section": "Reporting bugs",
    "text": "Reporting bugs\nContact us via the package GitHub site: https://github.com/PredictiveEcology/SpaDES/issues."
  },
  {
    "objectID": "posts/2015-08-10-Introducing-SpaDES.html",
    "href": "posts/2015-08-10-Introducing-SpaDES.html",
    "title": "Introducing SpaDES: R Package for Spatial Discrete Event Simulation",
    "section": "",
    "text": "v1.0.1 is now available on CRAN!\nBuilding spatial simulation models often involves reusing various model components, often having to re-implement similar functionality in multiple simulation frameworks (i.e, in different programming languages). When various components of a simulation model become fragmented across multiple platforms, it becomes increasingly difficult to link these various components, and often solutions for this problem are idiosyncratic and specific to the model being implemented. As a result, developing general insights into complex computational models has, in the field of ecology at least, been hampered by modellers’ typically developing models from scratch (Thiele, 2015).\nSpaDES is a generic simulation platform that can be used to create new model components quickly. It also provides a framework to link with existing simulation models, so that an already well described and mature model, e.g., Landis-II (Scheller, 2007), can be used with de novo components. Alternatively one could use several de novo models and several existing models in combination. This approach requires a platform that allows for modular reuse of model components (herein called ‘modules’) as hypotheses that can be evaluated and tested in various ways, as advocated by Thiele (2015).\nSpaDES makes it easy to implement a variety of simulation models including raster-based, event-based, and agent-based models. The core simulation components are built upon a discrete event simulation framework that facilitates modularity, and easily enables the user to include additional functionality by running user-built simulation modules. Included are numerous tools to rapidly visualize raster and other maps.\nWhen beginning development of this package, we sought a general simulation platform at least the following characteristics:\nWe selected R as the system within which to build SpaDES. R is currently the lingua franca for scientific data analysis. This means that anything developed in SpaDES is simply R code and can be easily shared with journals and the scientific community. We can likewise leverage R’s strengths as a data platform, its excellent visualization and graphics, its capabilities to run external code such as C/C++ and easily interact external software such as databases, and its abilities for high performance computing. SpaDES therefore doesn’t need to implement all of these from scratch, as they are achievable with already existing R packages."
  },
  {
    "objectID": "posts/2015-08-10-Introducing-SpaDES.html#getting-started",
    "href": "posts/2015-08-10-Introducing-SpaDES.html#getting-started",
    "title": "Introducing SpaDES: R Package for Spatial Discrete Event Simulation",
    "section": "Getting started",
    "text": "Getting started\n\nInstallation\n# install `SpaDES` from CRAN\ninstall.packages(\"SpaDES\")\n\n\n# install suggested package `fastshp`\n#  (requires development tools, e.g. Rtools)\ninstall.packages(\"fastshp\", repos=\"https://rforge.net\", type=\"source\")\n\n\nDocumentation\nVignettes:\nbrowseVignettes(package=\"SpaDES\")\nWebsite:\nhttps://SpaDES.PredictiveEcology.org\nWiki:\nhttps://github.com/PredictiveEcology/SpaDES/wiki"
  },
  {
    "objectID": "posts/2015-08-10-Introducing-SpaDES.html#reporting-bugs",
    "href": "posts/2015-08-10-Introducing-SpaDES.html#reporting-bugs",
    "title": "Introducing SpaDES: R Package for Spatial Discrete Event Simulation",
    "section": "Reporting bugs",
    "text": "Reporting bugs\nContact us via the package GitHub site: https://github.com/PredictiveEcology/SpaDES/issues."
  },
  {
    "objectID": "posts/2015-08-10-Introducing-SpaDES.html#references",
    "href": "posts/2015-08-10-Introducing-SpaDES.html#references",
    "title": "Introducing SpaDES: R Package for Spatial Discrete Event Simulation",
    "section": "References",
    "text": "References\nFall, A., & Fall, J. (2001). A domain-specific language for models of landscape dynamics. Ecological Modelling, 141, 1–18.\nScheller, R. M., Domingo, J. B., Sturtevant, B. R., Williams, J. S., Rudy, A., Gustafson, E. J., & Mladenoff, D. J. (2007). Design, development, and application of LANDIS-II, a spatial landscape simulation model with flexible temporal and spatial resolution. Ecological Modelling, 201, 409–419. doi:10.1016/j.ecolmodel.2006.10.009\nThiele, J. C., & Grimm, V. (2015). Replicating and breaking models: good for you and good for ecology. Oikos. doi:10.1111/oik.02170\nWilensky, U. (1999). NetLogo. Evanston, IL: Center for Connected Learning and Computer-Based Modeling, Northwestern University. https://ccl.northwestern.edu/netlogo"
  },
  {
    "objectID": "posts/2016-03-09-Removing-spaghetti-from-ecological-models.html",
    "href": "posts/2016-03-09-Removing-spaghetti-from-ecological-models.html",
    "title": "Removing spaghetti from ecological models",
    "section": "",
    "text": "Modularity requires a rethink for many people about how to build dependencies between models. Historically, ecological models were built as a single, large entity. Dependencies between different parts of the code base were deep, and hard to disentangle: spaghetti code. This has mostly changed over the past decade; however, the full revolution of modularity is still coming to ecological models."
  },
  {
    "objectID": "posts/2016-03-09-Removing-spaghetti-from-ecological-models.html#module-interdependency",
    "href": "posts/2016-03-09-Removing-spaghetti-from-ecological-models.html#module-interdependency",
    "title": "Removing spaghetti from ecological models",
    "section": "Module interdependency",
    "text": "Module interdependency\nWith SpaDES, we are promoting the idea of near zero model inter-dependency, except via their inputs or outputs. So, rather than say that a succession model has three modules that are dependent on one another along a sequence, like this:\n regeneration ---&gt;  growth ---------&gt; mortality\n     |               |                   |\n    \\|/             \\|/                 \\|/\n |stem counts |   |stem counts   |  |stem counts   |         \n | and size   |   |   and size   |  |   and size   |\n | by species |   |   by species |  |   by species |\n ------------     ---------------   ---------------\n; instead, we say that each takes inputs (i.e., data) and produces outputs (i.e., data) that are each definable:\nregeneration        _ growth          _ mortality\n         \\          /|     \\          /|          \\         \n         _\\|       /       _\\|       /            _\\|       \n       |stem counts |       |stem counts   |       |stem counts   |         \n       | and size   |       |   and size   |       |   and size   |\n       | by species |       |   by species |       |   by species |\n      ---------------       ----------------       ----------------\nSo, this means that we could “remove” the regeneration module, and the model will still work. We can remove the “growth” module and the model will still work. Whereas in the “interdependent” approach, it wouldn’t.\nNow the point is not to remove the growth module (what would that model do with just regen and mortality?)… but with this structure, we can replace the growth module with a different one and not break the modularity. Likewise, we can start a simulation with data of “stem counts and size by species”, rather than the output of the regen module or growth module or mortality module."
  },
  {
    "objectID": "posts/2016-03-09-Removing-spaghetti-from-ecological-models.html#next-blog-post-translator-modules",
    "href": "posts/2016-03-09-Removing-spaghetti-from-ecological-models.html#next-blog-post-translator-modules",
    "title": "Removing spaghetti from ecological models",
    "section": "Next blog post: Translator Modules",
    "text": "Next blog post: Translator Modules"
  },
  {
    "objectID": "posts/2016-04-13-SpaDES-v1.1.2-now-on-CRAN.html",
    "href": "posts/2016-04-13-SpaDES-v1.1.2-now-on-CRAN.html",
    "title": "SpaDES v1.1.2 now on CRAN",
    "section": "",
    "text": "v1.1.2 is now available on CRAN!\nThis release introduces several important additions and performance enhancements, as well as numerous bug fixes.\nThe main additions are:\nFor a complete list of changes, see the package’s NEWS file."
  },
  {
    "objectID": "posts/2016-04-13-SpaDES-v1.1.2-now-on-CRAN.html#getting-started-with-spades",
    "href": "posts/2016-04-13-SpaDES-v1.1.2-now-on-CRAN.html#getting-started-with-spades",
    "title": "SpaDES v1.1.2 now on CRAN",
    "section": "Getting started with SpaDES",
    "text": "Getting started with SpaDES\n\nInstallation\n# install `SpaDES` from CRAN\ninstall.packages(\"SpaDES\")\n\n\n# install suggested package `fastshp`\n#  (requires development tools, e.g., Rtools)\ninstall.packages(\"fastshp\", repos = \"https://rforge.net\", type = \"source\")\n\n\nDocumentation\nVignettes:\nAvailable at the wiki as well as in your R session:\nbrowseVignettes(package=\"SpaDES\")\nWebsite:\nhttps://SpaDES.PredictiveEcology.org\nWiki:\nhttps://github.com/PredictiveEcology/SpaDES/wiki"
  },
  {
    "objectID": "posts/2016-04-13-SpaDES-v1.1.2-now-on-CRAN.html#reporting-bugs",
    "href": "posts/2016-04-13-SpaDES-v1.1.2-now-on-CRAN.html#reporting-bugs",
    "title": "SpaDES v1.1.2 now on CRAN",
    "section": "Reporting bugs",
    "text": "Reporting bugs\nContact us via the package GitHub site: https://github.com/PredictiveEcology/SpaDES/issues."
  },
  {
    "objectID": "posts/2020-08-17-do.call-and-alist.html",
    "href": "posts/2020-08-17-do.call-and-alist.html",
    "title": "do.call and alist: a perfect match",
    "section": "",
    "text": "It has been a while between posts. So, lets dive in with a simple, but technical, one."
  },
  {
    "objectID": "posts/2020-08-17-do.call-and-alist.html#conclusion",
    "href": "posts/2020-08-17-do.call-and-alist.html#conclusion",
    "title": "do.call and alist: a perfect match",
    "section": "Conclusion",
    "text": "Conclusion\nAlways use alist when using do.call, even for small problems."
  },
  {
    "objectID": "posts/2016-01-08-Citation-List-On-GitHub.html",
    "href": "posts/2016-01-08-Citation-List-On-GitHub.html",
    "title": "Make a live publications page",
    "section": "",
    "text": "Creating a live web page with your publications is now easy to do and there are many ways to do so. I will show one that uses Zotero and GitHub."
  },
  {
    "objectID": "posts/2016-01-08-Citation-List-On-GitHub.html#prerequisites",
    "href": "posts/2016-01-08-Citation-List-On-GitHub.html#prerequisites",
    "title": "Make a live publications page",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nGithub page with gh-pages set up\nZotero database, synced with zotero.org"
  },
  {
    "objectID": "posts/2016-01-08-Citation-List-On-GitHub.html#optional",
    "href": "posts/2016-01-08-Citation-List-On-GitHub.html#optional",
    "title": "Make a live publications page",
    "section": "Optional",
    "text": "Optional\n\nA web redirection so that you don’t have to use the default web address: https://username.github.io . I won’d go into this here, but, it may be desireable to use a web address that is not the default."
  },
  {
    "objectID": "posts/2016-01-08-Citation-List-On-GitHub.html#steps",
    "href": "posts/2016-01-08-Citation-List-On-GitHub.html#steps",
    "title": "Make a live publications page",
    "section": "Steps",
    "text": "Steps\n\nGo to bibBase\nClick on the link to the right of Zotero part way down the page (Generate BibBase page …)\nYou will have to allow bibbase.org access to your zotero account\nClick on one of your Collections or Groups\nIf the page is correct, copy the URL at the top in the browser\nEmbed it in a markdown page:\n &lt;script src=\"https://bibbase.org/show?bib=[URL-OF-BIBTEX-FILE]&jsonp=1\"&gt;&lt;/script&gt;\nwhere you replace [URL-OF-BIBTEX-FILE] with the URL you just copied.\nSync your gh-pages.\nBrowse to your page to see it in action (e.g., https://predictiveecology.org/publications/\n\nIf you want a little bit of customization, see bibBase help for more."
  },
  {
    "objectID": "posts/2016-03-09-SpaDES_as_a_musical_conductor.html",
    "href": "posts/2016-03-09-SpaDES_as_a_musical_conductor.html",
    "title": "SpaDES as a musical conductor",
    "section": "",
    "text": "What is SpaDES? Powerful tools sometimes don’t lead to easy explanations of how they work. I recently got a room full of foresters, government researchers and policy people to sing some nursery rhymes to help explain it. See the talk here."
  },
  {
    "objectID": "posts/2016-01-26-SpaDES-v1.1.0-now-on-CRAN.html",
    "href": "posts/2016-01-26-SpaDES-v1.1.0-now-on-CRAN.html",
    "title": "SpaDES v1.1.0 now on CRAN",
    "section": "",
    "text": "v1.1.0 is now available on CRAN!\nSpaDES (Spatial Discrete Event Simulation) is a generic simulation platform that can be used to create new model components quickly. It’s’ easy to implement a variety of simulation models including raster-based, event-based, and agent-based models.\nThe latest version of SpaDES introduces several new features and fixes a number of issues from the previous 1.0.1 release, including:\nFor a complete list of changes, see the package’s NEWS file.\nPlease note that due to the number and scope of the enhancements, modules previously developed using the previous version may not work."
  },
  {
    "objectID": "posts/2016-01-26-SpaDES-v1.1.0-now-on-CRAN.html#getting-started-with-spades",
    "href": "posts/2016-01-26-SpaDES-v1.1.0-now-on-CRAN.html#getting-started-with-spades",
    "title": "SpaDES v1.1.0 now on CRAN",
    "section": "Getting started with SpaDES",
    "text": "Getting started with SpaDES\n\nInstallation\n# install `SpaDES` from CRAN\ninstall.packages(\"SpaDES\")\n\n\n# install suggested package `fastshp`\n#  (requires development tools, e.g., Rtools)\ninstall.packages(\"fastshp\", repos = \"https://rforge.net\", type = \"source\")\n\n\nDocumentation\nVignettes:\nAvailable at the wiki as well as in your R session:\nbrowseVignettes(package=\"SpaDES\")\nWebsite:\nhttps://SpaDES.PredictiveEcology.org\nWiki:\nhttps://github.com/PredictiveEcology/SpaDES/wiki"
  },
  {
    "objectID": "posts/2016-01-26-SpaDES-v1.1.0-now-on-CRAN.html#reporting-bugs",
    "href": "posts/2016-01-26-SpaDES-v1.1.0-now-on-CRAN.html#reporting-bugs",
    "title": "SpaDES v1.1.0 now on CRAN",
    "section": "Reporting bugs",
    "text": "Reporting bugs\nContact us via the package GitHub site: https://github.com/PredictiveEcology/SpaDES/issues."
  },
  {
    "objectID": "posts/2016-08-09-SpaDES-workshops.html",
    "href": "posts/2016-08-09-SpaDES-workshops.html",
    "title": "Introduction to SpaDES Workshop (updated)",
    "section": "",
    "text": "Updated September 9, 2016\nAlex Chubaty and I will be leading two introductory SpaDES workshops this fall. They will essentially be the same course, but one will be mid September, and the second will be in early December. We will be doing two workshops because there is immediate need for some users, but there are major travel restrictions for other users given the time frame.\n\nDates:\n\nWorkshop 1 - Sept 14-16, 2016\nWorkshop 2 - Dec 7-9, 2016 (tentative)\n\n\nBoth workshops:\nCost: Free\nWhere: Pacific Forestry Centre, Victoria, BC\nCurrent workshop outline"
  },
  {
    "objectID": "posts/2016-11-07-conditionally-end-SpaDES-simulation.html",
    "href": "posts/2016-11-07-conditionally-end-SpaDES-simulation.html",
    "title": "How do I end a simulation based on some condition other than time?",
    "section": "",
    "text": "SpaDES simulations typically start and end at a pre-specified times. So how do you end a simulation based on some other stopping criteria, such as when some variable reaches a particular value?\nSee my post on the SpaDES FAQ."
  },
  {
    "objectID": "posts/2016-06-24-SpaDES-v1.2.0-now-on-CRAN.html",
    "href": "posts/2016-06-24-SpaDES-v1.2.0-now-on-CRAN.html",
    "title": "SpaDES v1.2.0 now on CRAN",
    "section": "",
    "text": "v1.2.0 is now available on CRAN.\nThis release fixes a bug made apparent by the latest dplyr update, as well as several performance improvements and enhancements.\nFor a complete list of changes, see the package’s NEWS file."
  },
  {
    "objectID": "posts/2016-06-24-SpaDES-v1.2.0-now-on-CRAN.html#getting-started-with-spades",
    "href": "posts/2016-06-24-SpaDES-v1.2.0-now-on-CRAN.html#getting-started-with-spades",
    "title": "SpaDES v1.2.0 now on CRAN",
    "section": "Getting started with SpaDES",
    "text": "Getting started with SpaDES\n\nInstallation\n# install `SpaDES` from CRAN\ninstall.packages(\"SpaDES\")\n\n\n# install suggested package `fastshp`\n#  (requires development tools, e.g., Rtools)\ninstall.packages(\"fastshp\", repos = \"https://rforge.net\", type = \"source\")\n\n\nDocumentation\nVignettes:\nAvailable at the wiki as well as in your R session:\nbrowseVignettes(package=\"SpaDES\")\nWebsite:\nhttps://SpaDES.PredictiveEcology.org\nWiki:\nhttps://github.com/PredictiveEcology/SpaDES/wiki"
  },
  {
    "objectID": "posts/2016-06-24-SpaDES-v1.2.0-now-on-CRAN.html#reporting-bugs",
    "href": "posts/2016-06-24-SpaDES-v1.2.0-now-on-CRAN.html#reporting-bugs",
    "title": "SpaDES v1.2.0 now on CRAN",
    "section": "Reporting bugs",
    "text": "Reporting bugs\nContact us via the package GitHub site: https://github.com/PredictiveEcology/SpaDES/issues."
  },
  {
    "objectID": "posts/2016-10-21-Rmarkdown-science-workflow.html",
    "href": "posts/2016-10-21-Rmarkdown-science-workflow.html",
    "title": "Rmarkdown in a scientific workflow",
    "section": "",
    "text": "Using Rmarkdown with Rstudio and for all stages of my scientific projects has been a remarkable shift in how my work gets done! There are so many advantages to this type of workflow, not least of which are reproducibility and transparency (both are crucial for scientists as well as public servants). I’ve been using this approach as much as possible recently, and I’m quite happy with it. The entire process can be done using Rmarkdown etc. but there are still a few challenges which I’ll touch on below."
  },
  {
    "objectID": "posts/2016-10-21-Rmarkdown-science-workflow.html#what-is-rmarkdown",
    "href": "posts/2016-10-21-Rmarkdown-science-workflow.html#what-is-rmarkdown",
    "title": "Rmarkdown in a scientific workflow",
    "section": "What is Rmarkdown?",
    "text": "What is Rmarkdown?\nThe folks behind the RStudio IDE have completely changed how a majority of R users work with and program in R. Not only have they provided an exceptional IDE for working with and debugging R code, Rstudio also includes a number of important features that facilitate project management, package management, interactive graphics, and dynamic document generation.\nThis is where Rmarkdown come in.\nRmarkdown documents allow you to combine your “data, code, and narrative” in a single file, similar to project notebooks in MatLab, Mathematica, and others. This facilitates the integration of project development, data analyses, and report writing. Each of the components of your project can be tied together and, crucially, easily rerun when data are updated or changes need to be made to other steps in the research workflow.\nRmarkdown files follow the markdown mark up language, which is designed to be both human and machine readable. Although you edit .Rmd files in text form, the files are converted to their ‘final’ format (.pdf, .html, etc.) using the knitr package and pandoc. It is very easy to incorporate text, images, equations, code, etc. into .Rmd files which can then be rendered in a wide variety of file formats.\nImportantly, because Rmarkdown files (.Rmd) are text files, they are easily incorporated into a git or other version control system. This further enhances the utility of Rmarkdown for scientific projects because with version control, one can see the evolution of a project from start to finish."
  },
  {
    "objectID": "posts/2016-10-21-Rmarkdown-science-workflow.html#using-rmarkdown-throughout-the-scientific-workflow",
    "href": "posts/2016-10-21-Rmarkdown-science-workflow.html#using-rmarkdown-throughout-the-scientific-workflow",
    "title": "Rmarkdown in a scientific workflow",
    "section": "Using Rmarkdown throughout the scientific workflow",
    "text": "Using Rmarkdown throughout the scientific workflow\n\nInitial project conception\nMost (all?) researchers maintain a project notebook of some type to track the development of their projects. These notebooks are crucial for accountability and tracking project history and progress, and are invaluable references during the final stages of a project (i.e., writing manuscripts). Text, code, equations, and data can all be maintained in an .Rmd file. Handwritten project sketches and notes can also be digitized for inclusion.\n\n\nData analyses\nThis is where most discussion about using Rmarkdown occurs. R code is run and the output of analyses can be directly inserted into the text narrative, as inline results, separate code blocks, tables, and figures. This makes rerunning things a breeze, and can be used to generate dynamic reports.\nUsing version control, you don’t have to worry about maintaining old code and commenting it out as the project matures – just delete it (it’s still available in the version control history). This means you can always keep your .Rmd files up to date and ready to share with collaborators (or reviewers).\nOne important additional note: knitr supports caching of Rmarkdown code blocks, which means you don’t need to rerun all analyses when updating a report.\n\n\nCollaboration\nI use a collaborative workflow using R, Rmarkdown, and GitHub. However, most of my colleagues do not. This has been the most difficult challenge to overcome. How do I convince people to 1) adopt an open and reproducible workflow (e.g., use Rmarkdown instead of MS Word), and 2) use version control (i.e., git)?\nIn many cases, after spending some time with my colleagues to highlight the advantages and teach them how to use the tools, they are happily converted. However, even with most collaborators adopting this workflow, if even a single one doesn’t it can add additional work to my plate.\nCurrently, I’ll push changes to the project’s GitHub repository, usually tagging my collaborators in the relevant commit messages for them to take a look. I’ll also send an email (with the current version attached) and solicit feedback via GitHub.\nFor my collaborators using GitHub regularly, it’s easy – they make changes, we merge, and rebuild the documents as needed. But I still get emails back with a modified / annotated version of the file I sent out, which means I need to be the one to manually make changes and push them to GitHub. Getting (late) feedback on an old version of a draft sent out by email when the current GitHub version has seen substantial changes is even more frustrating to deal with. Annoying, but not the end of the world.\nI’m not discouraged! The time spend incorporating changes is mostly about copy-paste into the current version – no different than my old workflow using MS Word. I think the time saved in other parts of the workflow make up for the additional time spent here.\nI’m looking forward to more of my colleagues using .Rmd files, though I note that currently there is no good way of annotating documents. One method is to add text directly, which appears in the final rendered document. Another is to use HTML-style comments (&lt;!-- comments go here --&gt;) in the .Rmd file which will not appear in the final rendered document. Edit: Using GitHub directly to comment on specific lines within a commit can also work reasonably well, but you don’t get all annotations from multiple versions in a single location.\n\n\nPublication\nThis one is improving everyday. Basic article publication tools are already included with Rstudio and RMarkdown (including citations); however, for more advanced formatting there are other packages like rticles (which I’m using for my current manuscripts) and bookdown for book formatting. As a fallback, you can adopt HTML and LaTeX markup in your .Rmd files, and use additional CSS or LaTeX templates as needed.\nOwing to the long history of TeX in scientific publications, most journals not only accept .tex file submissions but also provide the necessary templates (some of these are included with the rticles package), and citation style (.csl) files can be downloaded from https://www.zotero.org/styles.\n\n\nCommunication\n\nEmail\nOne of the major selling points of markdown is that it’s a human-readable markup language (contrast against LaTeX or HTML). In principle, you can use markdown formatting for emails but most email programs will render them as text unless your recipient has a markdown converter (there are a few for e.g., Gmail).\n\n\nBlogs\nMost blogging platforms support markdown (by default or with additional plugins). This blog renders the markdown files (generated from .Rmd files) we upload into HTML format with all the appropriate syntax highlighting, etc. It’s a phenomenal way to create content locally and render the results reliably on a blog."
  },
  {
    "objectID": "posts/2016-10-21-Rmarkdown-science-workflow.html#final-thoughts",
    "href": "posts/2016-10-21-Rmarkdown-science-workflow.html#final-thoughts",
    "title": "Rmarkdown in a scientific workflow",
    "section": "Final thoughts",
    "text": "Final thoughts\nHow successful have I been? I firmly believe that adopting this new workflow has improved productivity as well as the calibre of the work I do. Especially over the medium to long term. Additionally, adopting a reproducible workflow not only improves scientific transparency and accountability, but it has enhanced the reusability of my work. Copying and pasting code from old projects actually works the first time – because I’m tracking these old projects using ‘living documentation’ that includes everything needed to run the code again: data, scripts, and associated explanations.\nIt’s worth the effort, and I encourage you to start using Rmarkdown."
  },
  {
    "objectID": "posts/2016-10-21-Rmarkdown-science-workflow.html#further-reading",
    "href": "posts/2016-10-21-Rmarkdown-science-workflow.html#further-reading",
    "title": "Rmarkdown in a scientific workflow",
    "section": "Further reading",
    "text": "Further reading\nGandrud, C. (2015). Reproducible Research with R and RStudio, 2nd edn. Chapman and Hall/CRC Press. https://github.com/christophergandrud/Rep-Res-Book\nRam, K. (2013). Git can facilitate greater reproducibility and increased transparency in science. Source Code for Biology and Medicine, 8(1), 7. https://doi.org/10.1186/1751-0473-8-7\nWilson, G., Aruliah, D. A., Brown, C. T., Chue Hong, N. P., Davis, M., Guy, R. T., … Wilson, P. (2014). Best practices for scientific computing. PLoS Biology, 12(1), e1001745. https://doi.org/10.1371/journal.pbio.1001745"
  },
  {
    "objectID": "posts/2016-10-15-SpaDES-workshop.html",
    "href": "posts/2016-10-15-SpaDES-workshop.html",
    "title": "Introduction to SpaDES Workshop (updated)",
    "section": "",
    "text": "Alex Chubaty and I will be leading a 2nd introductory SpaDES workshop this fall. This will essentially be the same course as the one offered in September, 2016.\n\nDates:\n\nWorkshop 2 - Dec 7-9, 2016\n\n\nBoth workshops:\nCost: Free\nWhere: Pacific Forestry Centre, Victoria, BC\nCurrent workshop outline"
  },
  {
    "objectID": "posts/2018-01-31-SpaDES-v2.0.1-now-on-CRAN.html",
    "href": "posts/2018-01-31-SpaDES-v2.0.1-now-on-CRAN.html",
    "title": "SpaDES v2.0.1 now on CRAN",
    "section": "",
    "text": "v2.0.1 is now available on CRAN.\nThis is a minor update that fixes backward compatibility with R version 3.3.0.\nThe core simulation components are provided by SpaDES.core), with additonal modelling tools provided by SpaDES.tools). Plotting is provided via quickPlot, and simulation caching methods via reproducible. Additional functionality is provided by the SpaDES.addins and SpaDES.shiny packages.\nThis release also includes several important bug fixes and and performance improvements to many of these spinoff packages.\nFor a complete list of changes, see the package’s NEWS file."
  },
  {
    "objectID": "posts/2018-01-31-SpaDES-v2.0.1-now-on-CRAN.html#installation",
    "href": "posts/2018-01-31-SpaDES-v2.0.1-now-on-CRAN.html#installation",
    "title": "SpaDES v2.0.1 now on CRAN",
    "section": "Installation",
    "text": "Installation\nInstall development libraries: building packages from source requires the appropriate development libraries for your operating system.\n\nWindows: install Rtools.\nmacOS: install Xcode commandline tools from the terminal: xcode-select install.\nDebian/Ubuntu Linux: ensure r-base-dev is installed.\n\nSee here for more details.\nInstall suggested packages: the fastshp package can be installed with:\ninstall.packages(\"fastshp\", repos = \"https://rforge.net\", type = \"source\")\n\nCurrent stable release\nInstall from CRAN:\ninstall.packages(\"SpaDES\")\nInstall from GitHub:\n#install.packages(\"devtools\")\nlibrary(\"devtools\")\ninstall_github(\"PredictiveEcology/SpaDES\", dependencies = TRUE) # stable\n\n\nDevelopment version (unstable)\nInstall from GitHub:\n#install.packages(\"devtools\")\nlibrary(\"devtools\")\ninstall_github(\"PredictiveEcology/SpaDES\", ref = \"development\", dependencies = TRUE) # unstable"
  },
  {
    "objectID": "posts/2018-01-31-SpaDES-v2.0.1-now-on-CRAN.html#getting-started",
    "href": "posts/2018-01-31-SpaDES-v2.0.1-now-on-CRAN.html#getting-started",
    "title": "SpaDES v2.0.1 now on CRAN",
    "section": "Getting started",
    "text": "Getting started\n\nGetting started guide\nVignettes\nWiki\nWorkshops"
  },
  {
    "objectID": "posts/2018-01-31-SpaDES-v2.0.1-now-on-CRAN.html#getting-help",
    "href": "posts/2018-01-31-SpaDES-v2.0.1-now-on-CRAN.html#getting-help",
    "title": "SpaDES v2.0.1 now on CRAN",
    "section": "Getting help",
    "text": "Getting help\n\nQ&A Forum"
  },
  {
    "objectID": "posts/2018-01-31-SpaDES-v2.0.1-now-on-CRAN.html#reporting-bugs",
    "href": "posts/2018-01-31-SpaDES-v2.0.1-now-on-CRAN.html#reporting-bugs",
    "title": "SpaDES v2.0.1 now on CRAN",
    "section": "Reporting bugs",
    "text": "Reporting bugs\nThe SpaDES metapackage simply loads a number of other packages from the SpaDES ecosystem. Bug reports should be reported to the specific package in question rather than the metapackage. Contact us via the package’s GitHub site:\n\nquickPlot\nreproducible\nSpaDES.addins\nSpaDES.core\nSpaDES.shiny\nSpaDES.tools"
  },
  {
    "objectID": "posts/2015-05-16-fpCompare.html",
    "href": "posts/2015-05-16-fpCompare.html",
    "title": "Reliable comparison of floating point numbers in R",
    "section": "",
    "text": "Version 0.2.0 of fpCompare has been released on CRAN\nComparisons of floating point numbers are problematic due to errors associated with the binary representation of decimal numbers. Computer scientists and programmers are aware of these problems and yet people still use numerical methods which fail to account for floating point errors (this pitfall is the first to be highlighted in Circle 1 of Burns (2012) The R Inferno).\nInspired by R FAQ 7.31 and this Stack Overflow answer, the fpCompare package provides new relational operators useful for performing floating point number comparisons with a set tolerance:\nThese functions use the base relational operators to make comparisons, but incorporate a tolerance value (fpCompare.tolerance), set via options. It uses the same default tolerance value used in all.equal for numeric comparisons."
  },
  {
    "objectID": "posts/2015-05-16-fpCompare.html#installation",
    "href": "posts/2015-05-16-fpCompare.html#installation",
    "title": "Reliable comparison of floating point numbers in R",
    "section": "Installation",
    "text": "Installation\n\nFrom CRAN\ninstall.packages(\"fpCompare\")\n\n\nFrom GitHub\nlibrary(devtools)\ninstall_github(\"PredictiveEcology/fpCompare\")"
  },
  {
    "objectID": "posts/2015-05-16-fpCompare.html#bug-reports",
    "href": "posts/2015-05-16-fpCompare.html#bug-reports",
    "title": "Reliable comparison of floating point numbers in R",
    "section": "Bug Reports",
    "text": "Bug Reports\nhttps://github.com/PredictiveEcology/fpCompare/issues"
  },
  {
    "objectID": "posts/2016-02-09-Summary-Statistics-SpaDES-Module.html",
    "href": "posts/2016-02-09-Summary-Statistics-SpaDES-Module.html",
    "title": "How do I calculate summary statistics and report them in a simulation?",
    "section": "",
    "text": "Often, we want to calculate some summary statistics from an object, such as a the mean value of a map, and plot that as a graph, updated at some interval, so that we can see how that statistic behaves over the simulation.\nWhat’s the best way to do this in a SpaDES simulation?\nSee Alex Chubaty’s post on the SpaDES FAQ"
  },
  {
    "objectID": "bios/community/tati.html",
    "href": "bios/community/tati.html",
    "title": "Dr Tati Micheletti",
    "section": "",
    "text": "webpage\n  \n  \n    \n     GitHub\n  \n\n      \nResearch Associate, TU Dresden, Germany.\nPreviously, Tati was a postdoc and research associate with at University of British Columbia from 2017-2023.\nTati has been asking questions about managing land in Canada when there are multiple, conflicting management pressures. She has been specializing in SpaDES model development, bird and caribou forecasting, protected areas optimization, and trade-offs/synergies across disciplines."
  },
  {
    "objectID": "bios/community/ceres.html",
    "href": "bios/community/ceres.html",
    "title": "Dr Ceres Barros",
    "section": "",
    "text": "webpage\n  \n  \n    \n     GitHub\n  \n  \n    \n     e-mail\n  \n\n      \nResearch Scientist, Natural Resources Canada\nAs part of the Predictive Ecology Lab, Ceres worked on mixed severity spatial fire modelling and the associated vegetation changes that go with it, as part of the Landscapes in Motion project. She then worked on on ecological forecasting of permafrost, disturbance, and vegetation in Northwest Territories, in a collaboration with the Forest Ecology Lab at Wilfrid Laurier University, as part of the Northern Water Futures project.\nAfter spending some time as Climate Change Research Ecologist at the BC Ministry of Forests, Ceres took a Research Scientist position at the Pacific Forestry Centre, Canadian Forest Service where she continues to actively collaborate with the Predictive Ecology Community."
  },
  {
    "objectID": "bios/community/aaaeliot.html",
    "href": "bios/community/aaaeliot.html",
    "title": "Dr Eliot McIntire",
    "section": "",
    "text": "webpage\n  \n  \n    \n     GitHub\n  \n  \n    \n     e-mail\n  \n\n      \nResearch Scientist, Natural Resources Canada\nAdjunct Professor, University of British Columbia & Université Laval\nMy research interests lie in applied ecology, conservation and forecasting of a broad array of ecosystems and species. Specifically, I am interested in using modern quantitative techniques to understand the natural complexity of ecosystems, ultimately, to allow forecasting of organisms and ecosystem processes. I use a variety of quantitative techniques, including Hierarchical Bayes, Spatial Analysis, Landscape Simulation Modeling, Structural Equation Modeling, and Non-Linear Models to achieve the best ecological inference from ecological data. Through each of the systems I study, I strive to understand the ecological processes and to test this understanding by forecasting."
  },
  {
    "objectID": "bios/community/barry.html",
    "href": "bios/community/barry.html",
    "title": "Dr. Barry Cooke",
    "section": "",
    "text": "webpage\n  \n  \n    \n     GitHub\n  \n  \n    \n     e-mail\n  \n\n      \nResearch Scientist, Natural Resources Canada"
  },
  {
    "objectID": "bios/community/julie.html",
    "href": "bios/community/julie.html",
    "title": "Dr Julie Turner",
    "section": "",
    "text": "webpage\n  \n  \n    \n     GitHub\n  \n\n      \nResearch Associate, Biodiversity Pathways.\nJulie has been collaborating with the Predictive Ecology group on issues related to caribou since 2021."
  },
  {
    "objectID": "bios/yong.html",
    "href": "bios/yong.html",
    "title": "Dr. Yong Luo",
    "section": "",
    "text": "LinkedIn\n  \n\n      \n(Postdoctoral Fellow 2017)"
  },
  {
    "objectID": "bios/jean.html",
    "href": "bios/jean.html",
    "title": "Dr. Jean Marchal",
    "section": "",
    "text": "webpage\n  \n\n      \n(PhD 2017)"
  },
  {
    "objectID": "bios/josh.html",
    "href": "bios/josh.html",
    "title": "Dr Josh Nowak",
    "section": "",
    "text": "webpage\n  \n\n      \n(PhD 2015)"
  },
  {
    "objectID": "bios/ian.html",
    "href": "bios/ian.html",
    "title": "Ian Eddy",
    "section": "",
    "text": "LinkedIn\n  \n\n      \n(Canadian Forest Service – Geospatial Scientist 2018 - )\nIan works part time with our team on various topics related to cumulative effects, GIS, SpaDES, modeling and data analytics."
  },
  {
    "objectID": "bios/current/isolde.html",
    "href": "bios/current/isolde.html",
    "title": "Isolde Lane Shaw",
    "section": "",
    "text": "webpage\n  \n\n      \n(PhD Student 2018 - )\nA student at Laval University."
  },
  {
    "objectID": "SpaDES.html",
    "href": "SpaDES.html",
    "title": "SpaDES",
    "section": "",
    "text": "SpaDES is a metapackage for R that facilitates PERFICT workflows. It began as a tool for spatial simulation for Ecology, but it has evolved over time."
  },
  {
    "objectID": "SpaDES.html#links",
    "href": "SpaDES.html#links",
    "title": "SpaDES",
    "section": "Links",
    "text": "Links\nSpaDES metapackage: https://SpaDES.PredictiveEcology.org\nSpaDES open discussions/questions: https://github.com/PredictiveEcology/SpaDES/discussions\nSpaDES wiki: https://github.com/PredictiveEcology/SpaDES/wiki\nOther SpaDES ecosystem packages:\n\nquickPlot: https://quickplot.predictiveecology.org/\nRequire: https://Require.predictiveecology.org/\nreproducible: https://reproducible.predictiveecology.org/\nSpaDES.addins: https://spades-addins.predictiveecology.org\nSpaDES.core: https://spades-core.predictiveecology.org/\nSpaDES.shiny: https://spades-shiny.predictiveecology.org/\nSpaDES.tools: https://spades-tools.predictiveecology.org/"
  },
  {
    "objectID": "workshops/June-2024-SpaDES-workshop.html",
    "href": "workshops/June-2024-SpaDES-workshop.html",
    "title": "Reproducible workflows for landscapes with SpaDES and PERFICT",
    "section": "",
    "text": "If you are interested in participating, please sign up here. Please also indicate preferences of which topics are of interest and at what level. We will attempt to customize the workshop accordingly.\n\nLoading…"
  },
  {
    "objectID": "presentations.html#invited-talks",
    "href": "presentations.html#invited-talks",
    "title": "Presentations",
    "section": "Invited Talks",
    "text": "Invited Talks"
  },
  {
    "objectID": "presentations.html#presentations",
    "href": "presentations.html#presentations",
    "title": "Presentations",
    "section": "Presentations",
    "text": "Presentations"
  }
]